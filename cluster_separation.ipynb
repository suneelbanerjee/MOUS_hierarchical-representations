{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_clusters(tmap_path, output_dir, threshold, extent_threshold=10):\n",
    "    \"\"\"\n",
    "    Separates non-contiguous clusters in a T-map into individual NIfTI masks,\n",
    "    applying a voxel count threshold (extent threshold).\n",
    "\n",
    "    Parameters:\n",
    "        tmap_path (str): Path to the input T-map NIfTI file.\n",
    "        output_dir (str): Directory to save the output NIfTI masks.\n",
    "        threshold (float): Threshold value to apply to the T-map.\n",
    "        extent_threshold (int): Minimum number of voxels for a cluster to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list of cluster paths, affine transformation matrix)\n",
    "    \"\"\"\n",
    "    # Load the T-map\n",
    "    tmap_img = nib.load(tmap_path)\n",
    "    tmap_data = tmap_img.get_fdata()\n",
    "\n",
    "    # Apply threshold\n",
    "    thresholded_data = tmap_data > threshold\n",
    "\n",
    "    # Label clusters\n",
    "    labeled_data, num_clusters = label(thresholded_data)\n",
    "    print(f\"Found {num_clusters} clusters (before extent threshold).\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save each cluster that meets the extent threshold\n",
    "    cluster_paths = []\n",
    "    retained_clusters = 0\n",
    "    for cluster_id in range(1, num_clusters + 1):\n",
    "        cluster_mask = (labeled_data == cluster_id).astype(np.int16)\n",
    "        # Count the number of voxels in the cluster\n",
    "        voxel_count = np.sum(cluster_mask)\n",
    "\n",
    "        # Skip clusters that do not meet the extent threshold\n",
    "        if voxel_count < extent_threshold:\n",
    "            continue\n",
    "\n",
    "        # Save the cluster mask\n",
    "        cluster_img = nib.Nifti1Image(cluster_mask, affine=tmap_img.affine, header=tmap_img.header)\n",
    "        output_path = os.path.join(output_dir, f\"cluster_{retained_clusters + 1}.nii\")\n",
    "        nib.save(cluster_img, output_path)\n",
    "        cluster_paths.append(output_path)\n",
    "        retained_clusters += 1\n",
    "        print(f\"Saved cluster {retained_clusters} with {voxel_count} voxels to {output_path}\")\n",
    "\n",
    "    print(f\"Retained {retained_clusters} clusters (after extent threshold).\")\n",
    "\n",
    "    # Return cluster paths and the affine matrix\n",
    "    return cluster_paths, tmap_img.affine\n",
    "\n",
    "\n",
    "def calculate_centroids_and_peaks(cluster_paths, tmap_path):\n",
    "    \"\"\"\n",
    "    Calculates the centroid and peak coordinates of each cluster.\n",
    "\n",
    "    Parameters:\n",
    "        cluster_paths (list): List of paths to cluster NIfTI masks.\n",
    "        tmap_path (str): Path to the original T-map NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries for each cluster containing centroid and peak coordinates.\n",
    "    \"\"\"\n",
    "    # Load the T-map\n",
    "    tmap_img = nib.load(tmap_path)\n",
    "    tmap_data = tmap_img.get_fdata()\n",
    "\n",
    "    results = []\n",
    "    for cluster_path in cluster_paths:\n",
    "        # Load the cluster mask\n",
    "        cluster_img = nib.load(cluster_path)\n",
    "        cluster_data = cluster_img.get_fdata()\n",
    "\n",
    "        # Mask the T-map with the cluster mask\n",
    "        weighted_data = cluster_data * tmap_data\n",
    "\n",
    "        # Find voxel coordinates\n",
    "        coords = np.array(np.nonzero(cluster_data))\n",
    "        weights = weighted_data[cluster_data > 0]\n",
    "\n",
    "        # Calculate the weighted centroid\n",
    "        if weights.sum() > 0:\n",
    "            centroid = np.average(coords, axis=1, weights=weights)\n",
    "            # Transform centroid to world coordinates\n",
    "            centroid_world = nib.affines.apply_affine(tmap_img.affine, centroid)\n",
    "        else:\n",
    "            centroid_world = (np.nan, np.nan, np.nan)  # In case of no weights\n",
    "\n",
    "        # Find the peak coordinate (voxel with the highest T-statistic)\n",
    "        peak_voxel_index = np.unravel_index(np.argmax(weighted_data, axis=None), cluster_data.shape)\n",
    "        peak_world = nib.affines.apply_affine(tmap_img.affine, peak_voxel_index)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"centroid\": tuple(centroid_world),\n",
    "            \"peak\": tuple(peak_world)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Updated to include peak T value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/spmT_0001.nii\n",
      "/home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/cluster_centroids.csv\n"
     ]
    }
   ],
   "source": [
    "# thresholded_binary = '/Users/neel/Desktop/SPM-V_II_Zipf_multireg (FINAL)/VisualWord_roi.nii'\n",
    "roi_output_dir = '/home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi'\n",
    "if not os.path.exists(roi_output_dir):\n",
    "    os.makedirs(roi_output_dir)\n",
    "tmap = str(Path(roi_output_dir).parent / 'spmT_0001.nii')\n",
    "print(tmap)\n",
    "save_path = str(Path(roi_output_dir).parent / 'cluster_centroids.csv')\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 clusters (before extent threshold).\n",
      "Saved cluster 1 with 214 voxels to /home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi/cluster_1.nii\n",
      "Saved cluster 2 with 186 voxels to /home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi/cluster_2.nii\n",
      "Saved cluster 3 with 97 voxels to /home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi/cluster_3.nii\n",
      "Saved cluster 4 with 416 voxels to /home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi/cluster_4.nii\n",
      "Saved cluster 5 with 63 voxels to /home/neel/Documents/SPM_results/second_level/SPM-V_II_Lg10BG_multireg_november/roi/cluster_5.nii\n",
      "Retained 5 clusters (after extent threshold).\n"
     ]
    }
   ],
   "source": [
    "#delete all the contents of the roi_output_dir before running the code\n",
    "for file in os.listdir(roi_output_dir):\n",
    "    os.remove(os.path.join(roi_output_dir, file))\n",
    "cluster_paths, affine = separate_clusters(tmap, roi_output_dir, 7.41,extent_threshold=20)\n",
    "results = calculate_centroids_and_peaks(cluster_paths, tmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      "  Centroid = [-24, -92, -9]\n",
      "  Peak = [-18, -94, -8]\n",
      "  Peak T-value = 12.8\n",
      "  Extent = 416 voxels\n",
      "Cluster 2:\n",
      "  Centroid = [-55, -9, -10]\n",
      "  Peak = [-58, -10, -8]\n",
      "  Peak T-value = 10.79\n",
      "  Extent = 186 voxels\n",
      "Cluster 3:\n",
      "  Centroid = [-54, -36, 3]\n",
      "  Peak = [-50, -38, 2]\n",
      "  Peak T-value = 10.04\n",
      "  Extent = 214 voxels\n",
      "Cluster 4:\n",
      "  Centroid = [-49, 32, 1]\n",
      "  Peak = [-46, 32, -2]\n",
      "  Peak T-value = 9.15\n",
      "  Extent = 97 voxels\n",
      "Cluster 5:\n",
      "  Centroid = [24, -93, -4]\n",
      "  Peak = [24, -96, -2]\n",
      "  Peak T-value = 8.83\n",
      "  Extent = 63 voxels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate peak T-values and store results\n",
    "sorted_results = []\n",
    "for i, result in enumerate(results, start=1):\n",
    "    centroid = [round(coord) for coord in result[\"centroid\"]]\n",
    "    peak = [round(coord) for coord in result[\"peak\"]]\n",
    "    \n",
    "    # Load the T-map to get the peak T-value\n",
    "    tmap_img = nib.load(tmap)\n",
    "    tmap_data = tmap_img.get_fdata()\n",
    "    \n",
    "    # Convert the peak coordinate from world space to voxel space\n",
    "    peak_voxel = np.round(nib.affines.apply_affine(np.linalg.inv(tmap_img.affine), result[\"peak\"])).astype(int)\n",
    "    \n",
    "    # Ensure the voxel indices are within bounds\n",
    "    if (0 <= peak_voxel[0] < tmap_data.shape[0] and\n",
    "        0 <= peak_voxel[1] < tmap_data.shape[1] and\n",
    "        0 <= peak_voxel[2] < tmap_data.shape[2]):\n",
    "        peak_t_value = tmap_data[tuple(peak_voxel)]\n",
    "    else:\n",
    "        peak_t_value = float('nan')  # Out of bounds, assign NaN\n",
    "\n",
    "    # Calculate cluster size in voxels\n",
    "    cluster_path = cluster_paths[i - 1]\n",
    "    cluster_img = nib.load(cluster_path)\n",
    "    cluster_data = cluster_img.get_fdata()\n",
    "    cluster_size = int(np.sum(cluster_data > 0))  # Count non-zero voxels\n",
    "\n",
    "    sorted_results.append({\n",
    "        'Cluster #': i,\n",
    "        'Centroid': centroid,\n",
    "        'Peak': peak,\n",
    "        'Peak T-value': peak_t_value,\n",
    "        'Extent': cluster_size\n",
    "    })\n",
    "\n",
    "# Sort results by peak T-value in descending order\n",
    "sorted_results.sort(key=lambda x: x['Peak T-value'], reverse=True)\n",
    "\n",
    "# Reassign cluster numbers in order\n",
    "for i, result in enumerate(sorted_results, start=1):\n",
    "    result['Cluster #'] = i\n",
    "\n",
    "# Print sorted results\n",
    "for result in sorted_results:\n",
    "    print(f\"Cluster {result['Cluster #']}:\")\n",
    "    print(f\"  Centroid = {result['Centroid']}\")\n",
    "    print(f\"  Peak = {result['Peak']}\")\n",
    "    print(f\"  Peak T-value = {round(result['Peak T-value'], 2)}\")\n",
    "    print(f\"  Extent = {result['Extent']} voxels\")\n",
    "\n",
    "# Save sorted results to a CSV file\n",
    "with open(save_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Cluster #', 'Centroid', 'Peak', 'Peak T-value', 'Extent']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in sorted_results:\n",
    "        writer.writerow({\n",
    "            'Cluster #': result['Cluster #'],\n",
    "            'Centroid': result['Centroid'],\n",
    "            'Peak': result['Peak'],\n",
    "            'Peak T-value': round(result['Peak T-value'], 2),\n",
    "            'Extent': result['Extent']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
