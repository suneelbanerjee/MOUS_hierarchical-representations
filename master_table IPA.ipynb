{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>CDlow</th>\n",
       "      <th>FREQlemma</th>\n",
       "      <th>SUBTLEXWF</th>\n",
       "      <th>Zipf</th>\n",
       "      <th>SUBTLEXCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "      <th>dominant.pos</th>\n",
       "      <th>dominant.pos.freq</th>\n",
       "      <th>dominant.pos.lemma</th>\n",
       "      <th>dominant.pos.lemma.freq</th>\n",
       "      <th>all.pos</th>\n",
       "      <th>all.pos.freq</th>\n",
       "      <th>all.pos.lemma.freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ik</td>\n",
       "      <td>1744062</td>\n",
       "      <td>8054</td>\n",
       "      <td>778704</td>\n",
       "      <td>3125</td>\n",
       "      <td>1744527</td>\n",
       "      <td>39883.0334</td>\n",
       "      <td>7.597064</td>\n",
       "      <td>99.8017</td>\n",
       "      <td>3.9061</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1743609</td>\n",
       "      <td>ik</td>\n",
       "      <td>1743944</td>\n",
       "      <td>.VNW.SPEC.N.VZ.</td>\n",
       "      <td>.1743609.448.4.1.</td>\n",
       "      <td>.1743944.448.134.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>1600888</td>\n",
       "      <td>8060</td>\n",
       "      <td>1315051</td>\n",
       "      <td>6535</td>\n",
       "      <td>1600923</td>\n",
       "      <td>36608.9449</td>\n",
       "      <td>7.559864</td>\n",
       "      <td>99.8761</td>\n",
       "      <td>3.9064</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1600798</td>\n",
       "      <td>je</td>\n",
       "      <td>1600798</td>\n",
       "      <td>.VNW.SPEC.N.BW.LID.</td>\n",
       "      <td>.1600798.72.15.2.1.</td>\n",
       "      <td>.1600798.72.50.2.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het</td>\n",
       "      <td>1068396</td>\n",
       "      <td>8066</td>\n",
       "      <td>780771</td>\n",
       "      <td>5578</td>\n",
       "      <td>1913811</td>\n",
       "      <td>24431.9717</td>\n",
       "      <td>7.384235</td>\n",
       "      <td>99.9504</td>\n",
       "      <td>3.9067</td>\n",
       "      <td>VNW</td>\n",
       "      <td>735390</td>\n",
       "      <td>het</td>\n",
       "      <td>735395</td>\n",
       "      <td>.VNW.LID.SPEC.WW.N.</td>\n",
       "      <td>.735390.332929.53.22.2.</td>\n",
       "      <td>.735395.332929.53.845403.31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>1061177</td>\n",
       "      <td>8070</td>\n",
       "      <td>903872</td>\n",
       "      <td>6512</td>\n",
       "      <td>1063827</td>\n",
       "      <td>24266.8883</td>\n",
       "      <td>7.381291</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.9069</td>\n",
       "      <td>LID</td>\n",
       "      <td>1060098</td>\n",
       "      <td>de</td>\n",
       "      <td>1062748</td>\n",
       "      <td>.LID.VNW.SPEC.VZ.</td>\n",
       "      <td>.1060098.806.272.1.</td>\n",
       "      <td>.1062748.806.272.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dat</td>\n",
       "      <td>965424</td>\n",
       "      <td>8063</td>\n",
       "      <td>715570</td>\n",
       "      <td>6107</td>\n",
       "      <td>965431</td>\n",
       "      <td>22077.2184</td>\n",
       "      <td>7.340221</td>\n",
       "      <td>99.9133</td>\n",
       "      <td>3.9066</td>\n",
       "      <td>VNW</td>\n",
       "      <td>532576</td>\n",
       "      <td>dat</td>\n",
       "      <td>532576</td>\n",
       "      <td>.VNW.VG.SPEC.N.WW.</td>\n",
       "      <td>.532576.432794.51.2.1.</td>\n",
       "      <td>.532576.432794.51.9.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437498</th>\n",
       "      <td>&amp;_blake</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_blake</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437499</th>\n",
       "      <td>&amp;_barbie</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_barbie</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437500</th>\n",
       "      <td>&amp;_bake_pizza</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_bake_pizza</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437501</th>\n",
       "      <td>&amp;_bach</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_bach</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437502</th>\n",
       "      <td>&amp;_atlantic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_atlantic</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437503 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  FREQcount  CDcount  FREQlow  CDlow  FREQlemma  \\\n",
       "0                 ik    1744062     8054   778704   3125    1744527   \n",
       "1                 je    1600888     8060  1315051   6535    1600923   \n",
       "2                het    1068396     8066   780771   5578    1913811   \n",
       "3                 de    1061177     8070   903872   6512    1063827   \n",
       "4                dat     965424     8063   715570   6107     965431   \n",
       "...              ...        ...      ...      ...    ...        ...   \n",
       "437498       &_blake          1        1        1      1          1   \n",
       "437499      &_barbie          1        1        1      1          1   \n",
       "437500  &_bake_pizza          1        1        1      1          1   \n",
       "437501        &_bach          1        1        1      1          1   \n",
       "437502    &_atlantic          1        1        1      1          1   \n",
       "\n",
       "         SUBTLEXWF      Zipf  SUBTLEXCD  Lg10CD dominant.pos  \\\n",
       "0       39883.0334  7.597064    99.8017  3.9061          VNW   \n",
       "1       36608.9449  7.559864    99.8761  3.9064          VNW   \n",
       "2       24431.9717  7.384235    99.9504  3.9067          VNW   \n",
       "3       24266.8883  7.381291   100.0000  3.9069          LID   \n",
       "4       22077.2184  7.340221    99.9133  3.9066          VNW   \n",
       "...            ...       ...        ...     ...          ...   \n",
       "437498      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437499      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437500      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437501      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437502      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "\n",
       "        dominant.pos.freq dominant.pos.lemma  dominant.pos.lemma.freq  \\\n",
       "0                 1743609                 ik                  1743944   \n",
       "1                 1600798                 je                  1600798   \n",
       "2                  735390                het                   735395   \n",
       "3                 1060098                 de                  1062748   \n",
       "4                  532576                dat                   532576   \n",
       "...                   ...                ...                      ...   \n",
       "437498                  1            &_blake                        1   \n",
       "437499                  1           &_barbie                        1   \n",
       "437500                  1       &_bake_pizza                        1   \n",
       "437501                  1             &_bach                        1   \n",
       "437502                  1         &_atlantic                        1   \n",
       "\n",
       "                    all.pos             all.pos.freq  \\\n",
       "0           .VNW.SPEC.N.VZ.        .1743609.448.4.1.   \n",
       "1       .VNW.SPEC.N.BW.LID.      .1600798.72.15.2.1.   \n",
       "2       .VNW.LID.SPEC.WW.N.  .735390.332929.53.22.2.   \n",
       "3         .LID.VNW.SPEC.VZ.      .1060098.806.272.1.   \n",
       "4        .VNW.VG.SPEC.N.WW.   .532576.432794.51.2.1.   \n",
       "...                     ...                      ...   \n",
       "437498               .SPEC.                      .1.   \n",
       "437499               .SPEC.                      .1.   \n",
       "437500               .SPEC.                      .1.   \n",
       "437501               .SPEC.                      .1.   \n",
       "437502               .SPEC.                      .1.   \n",
       "\n",
       "                  all.pos.lemma.freq  \n",
       "0                .1743944.448.134.1.  \n",
       "1                .1600798.72.50.2.1.  \n",
       "2       .735395.332929.53.845403.31.  \n",
       "3                .1062748.806.272.1.  \n",
       "4             .532576.432794.51.9.1.  \n",
       "...                              ...  \n",
       "437498                           .1.  \n",
       "437499                           .1.  \n",
       "437500                           .1.  \n",
       "437501                           .1.  \n",
       "437502                           .1.  \n",
       "\n",
       "[437503 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtlex_v2 = pd.read_excel('/home/neel/Desktop/sublexical_crossmodal/SUBTLEX-NL with pos and Zipf.xlsx')\n",
    "subtlex_v1 = pd.read_csv('/home/neel/Desktop/sublexical_crossmodal/SUBTLEX-NL-utf8.txt',delimiter = '\\t')\n",
    "subtlex = subtlex_v2\n",
    "subtlex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_syllables = pd.read_csv('/home/neel/Desktop/sublexical_crossmodal/dutch_celex_database_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = celex_syllables['phone_full'].apply(lambda x: x.split('-'))\n",
    "syllables_unique = []\n",
    "for word in syllables:\n",
    "    for syl in word:\n",
    "            syllables_unique.append(syl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(syllables_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove apostrophes from every term in syllables_unique\n",
    "# syllables_unique = [syl.replace(\"'\", \"\") for syl in syllables_unique]  \n",
    "# #remove apostrophes from every term in celex_syllables['phone_full']\n",
    "# celex_syllables['phone_full'] = celex_syllables['phone_full'].apply(lambda x: x.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = celex_syllables[['Head','phone_full']]\n",
    "new_df.rename(columns = {'Head':'Word', 'phone_full':'Syllables'}, inplace = True)\n",
    "#merge new_df with subtlex on 'Word' but only keep 'FREQcount' and 'Zipf' from subtlex\n",
    "new_df = new_df.merge(subtlex[['Word','FREQcount','Zipf']], on = 'Word', how = 'left')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with NaN values in FREQcount\n",
    "#new_df = new_df.dropna(subset = ['FREQcount'])\n",
    "#reset index\n",
    "new_df = new_df.reset_index(drop = True)\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(columns ={'Syllables':'Phonetic'}, inplace = True)\n",
    "new_df['Syllables'] = new_df['Phonetic'].apply(lambda x: x.split('-'))\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('/home/neel/Desktop/sublexical_crossmodal/subtlex_v2_celex_intersect_phonetic_counts.csv', index = False)\n",
    "#new_df.to_excel('/home/neel/Desktop/sublexical_crossmodal/subtlex_v2_celex_intersect_phonetic_counts.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates in syllables_unique\n",
    "syllables_unique = list(set(syllables_unique))\n",
    "len(syllables_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to count occurrences of each syllable\n",
    "syllable_counts = {syllable: 0 for syllable in syllables_unique}\n",
    "print(len(syllable_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each syllable and use list comprehension to count occurrences\n",
    "for syllable in syllables_unique:\n",
    "    # Create a boolean mask where the syllable is present in the 'Syllables' column\n",
    "    mask = new_df['Syllables'].apply(lambda x: syllable in x)\n",
    "    # Sum the 'FREQcount' values where the mask is True\n",
    "    syllable_counts[syllable] = new_df.loc[mask, 'FREQcount'].sum()\n",
    "\n",
    "# Print the count of each syllable\n",
    "for syllable, count in syllable_counts.items():\n",
    "    print(f\"Syllable: {syllable}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(syllable_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save syllable_counts to a csv file\n",
    "syllable_counts_df = pd.DataFrame.from_dict(syllable_counts, orient = 'index', columns = ['Count'])\n",
    "syllable_counts_df.to_csv('syllable_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "csv_file_path = 'syllable_counts.csv'\n",
    "syllable_counts_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure the column names are valid MATLAB variable names\n",
    "syllable_counts_df.columns = ['syllable', 'Count']\n",
    "\n",
    "# Convert the DataFrame to a dictionary of arrays, making sure each column is a separate entry\n",
    "syllable_table_dict = {}\n",
    "for col in syllable_counts_df.columns:\n",
    "    syllable_table_dict[col] = syllable_counts_df[col].values\n",
    "\n",
    "# Save the dictionary as a MATLAB file\n",
    "new_mat_file_path = 'syllable_freq_table_new.mat'\n",
    "scipy.io.savemat(new_mat_file_path, syllable_table_dict)\n",
    "\n",
    "print(f\"Updated .mat file saved at: {new_mat_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOUS word phonetic transcriptions. how many words are there whose syllables are uncounted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barkeeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irritante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>blije</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>jongeren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>intens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>plezier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>woonplaats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word\n",
       "0           toen\n",
       "1             de\n",
       "2      barkeeper\n",
       "3            die\n",
       "4      irritante\n",
       "...          ...\n",
       "1937       blije\n",
       "1938    jongeren\n",
       "1939      intens\n",
       "1940     plezier\n",
       "1941  woonplaats\n",
       "\n",
       "[1942 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli = 'stimuli.txt'\n",
    "#remove all numbers and make every word in the txt a row in a dataframe column\n",
    "with open(stimuli, 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "#remove all numbers\n",
    "mous_words = []\n",
    "for line in words:\n",
    "    tokens = line.split(\" \")\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "            tokens.remove(token)\n",
    "    mous_words.extend([token.lower() for token in tokens if token != ''])\n",
    "#make a dataframe\n",
    "mous_words = pd.DataFrame(mous_words, columns = ['Word'])\n",
    "mous_words.drop_duplicates(inplace = True)\n",
    "mous_words.reset_index(drop = True, inplace = True)\n",
    "mous_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the word in words that contains an apostrophe\n",
    "for word in mous_words['Word']:\n",
    "    if \"'\" in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersect mous_words with new_df on 'Word'\n",
    "mous_words = mous_words.merge(new_df[['Word','Syllables']], on = 'Word', how = 'left')\n",
    "mous_words.drop_duplicates(subset = 'Word', inplace = True)\n",
    "mous_words = mous_words.reset_index(drop = True)\n",
    "mous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan values\n",
    "#mous_words = mous_words.dropna()\n",
    "mous_words.reset_index(drop = True, inplace = True)\n",
    "mous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_syllables(x):\n",
    "    # Check if x is a list (or any iterable except for strings), then proceed with the original operation.\n",
    "    if isinstance(x, list):\n",
    "        return [syllable_counts[syl] for syl in x]\n",
    "    # If x is not a list, return a default value, e.g., an empty list or a list with a specific value indicating the error.\n",
    "    else:\n",
    "        return []  # or return [0] or any other placeholder value that makes sense in your context\n",
    "\n",
    "# Apply the modified function\n",
    "mous_words['Syllable Occurrence Counts'] = mous_words['Syllables'].apply(handle_syllables)\n",
    "mous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mous_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a list of all bigrams possible in the alphabet\n",
    "import string\n",
    "alphabet = string.ascii_lowercase\n",
    "bigrams = []\n",
    "for letter1 in alphabet:\n",
    "    for letter2 in alphabet:\n",
    "        bigrams.append(letter1 + letter2)\n",
    "bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the cumulative occurrence of each bigram in the subtlex dataframe\n",
    "bigram_counts = {bigram: 0 for bigram in bigrams}\n",
    "for bigram in bigrams:\n",
    "    # Ensure x is treated as a string, even if it's originally a float\n",
    "    mask = subtlex_v2['Word'].apply(lambda x: bigram in str(x))\n",
    "    bigram_counts[bigram] = new_df.loc[mask, 'FREQcount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframe and csv from bigram_counts\n",
    "bigram_counts_df = pd.DataFrame.from_dict(bigram_counts, orient = 'index', columns = ['Count'])\n",
    "#make index a column\n",
    "bigram_counts_df.reset_index(inplace = True)\n",
    "bigram_counts_df.rename(columns = {'index':'Bigram'}, inplace = True)\n",
    "bigram_counts_df.to_csv('/home/neel/Desktop/sublexical_crossmodal/bigram_counts.csv')\n",
    "bigram_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word_bigrams(word):\n",
    "    # Split the word into bigrams\n",
    "    bigrams = [word[i:i+2] for i in range(len(word) - 1)]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mous_words['Bigrams'] = mous_words['Word'].apply(split_word_bigrams)\n",
    "mous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mous_words['Bigram Occurrence Counts'] = mous_words['Bigrams'].apply(lambda x: [bigram_counts.get(bigram, 0) for bigram in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mous_words['Zipf'] = mous_words['Word'].apply(lambda x: subtlex_v2.loc[subtlex_v2['Word'] == x, 'Zipf'].values[0] if x in subtlex_v2['Word'].values else np.nan)\n",
    "mous_words['FREQcount'] = mous_words['Word'].apply(lambda x: (subtlex_v2.loc[subtlex_v2['Word'] == x, 'FREQcount'].values[0]) if x in subtlex_v2['Word'].values else np.nan)\n",
    "mous_words['Lg10WF'] = mous_words['FREQcount'].apply(lambda x: np.log10(x) if x > 0 else 0)\n",
    "mous_words.to_csv('/home/neel/Desktop/MOUS_hierarchical-representations/mous_words_syllable_bigram_frequencies.csv', index = False)\n",
    "mous_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data summary.\n",
    "\n",
    "`1942` unique words in the MOUS study.\n",
    "\n",
    "    `X` have syllable parcellations\n",
    "\n",
    "    `Y` have bigram parcellations\n",
    "\n",
    "    `4` have apostrophes (see above)\n",
    "\n",
    "\n",
    "`A` unique words in SUBTLEX, `B` unique words in CELEX\n",
    "\n",
    "    `C` (overlap) have syllable parcellations from CELEX (matters for syllable frequency calculations)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of rows in mous_words that are non-Nan in 'Syllables'\n",
    "#return X_words, a dataframe of all words in mous_words that have syllables\n",
    "#return missing_words, a dataframe of all words in mous_words that do not have syllables\n",
    "X_words = mous_words.dropna(subset = ['Syllables'])\n",
    "X = mous_words['Syllables'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = mous_words[mous_words['Syllables'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of rows in mous_words that are non-Nan in 'Bigrams'\n",
    "Y = mous_words['Bigrams'].count()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = subtlex_v2['Word'].count()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = celex_syllables['Head'].count()\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = new_df['Zipf'].count()\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "International Phonetic Alphabet (IPA) transcriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtlex_words = list(subtlex['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ik',\n",
       " 'je',\n",
       " 'het',\n",
       " 'de',\n",
       " 'dat',\n",
       " 'is',\n",
       " 'niet',\n",
       " 'een',\n",
       " 'en',\n",
       " 'wat',\n",
       " 'van',\n",
       " 'we',\n",
       " 'ze',\n",
       " 'hij',\n",
       " 'in',\n",
       " 'maar',\n",
       " 'er',\n",
       " 'op',\n",
       " 'zijn',\n",
       " 'te',\n",
       " 'me',\n",
       " 'die',\n",
       " 'heb',\n",
       " 'met',\n",
       " 'voor',\n",
       " 'als',\n",
       " 'u',\n",
       " 'ben',\n",
       " 'was',\n",
       " 'dit',\n",
       " 'hier',\n",
       " 'jij',\n",
       " 'naar',\n",
       " 'om',\n",
       " 'mijn',\n",
       " 'weet',\n",
       " 'dan',\n",
       " 'wel',\n",
       " 'kan',\n",
       " 'nog',\n",
       " 'wil',\n",
       " 'geen',\n",
       " 'moet',\n",
       " 'zo',\n",
       " 'aan',\n",
       " 'hem',\n",
       " 'heeft',\n",
       " 'goed',\n",
       " 'hebben',\n",
       " 'ja',\n",
       " 'hoe',\n",
       " 'waar',\n",
       " 'nu',\n",
       " 'nee',\n",
       " 'haar',\n",
       " 'ga',\n",
       " \"'t\",\n",
       " 'bent',\n",
       " 'uit',\n",
       " 'ook',\n",
       " 'over',\n",
       " 'doen',\n",
       " 'gaan',\n",
       " 'kom',\n",
       " 'mij',\n",
       " 'daar',\n",
       " 'zou',\n",
       " 'bij',\n",
       " 'al',\n",
       " 'of',\n",
       " 'jullie',\n",
       " 'ons',\n",
       " 'gaat',\n",
       " 'iets',\n",
       " 'hebt',\n",
       " 'zal',\n",
       " 'waarom',\n",
       " \"m'n\",\n",
       " 'had',\n",
       " \"'n\",\n",
       " 'meer',\n",
       " 'laat',\n",
       " 'doe',\n",
       " 'wie',\n",
       " 'moeten',\n",
       " 'deze',\n",
       " 'alles',\n",
       " 'kunnen',\n",
       " 'jou',\n",
       " 'toch',\n",
       " 'echt',\n",
       " 'denk',\n",
       " 'zien',\n",
       " 'weg',\n",
       " 'nou',\n",
       " 'alleen',\n",
       " 'nooit',\n",
       " 'door',\n",
       " 'mee',\n",
       " 'dus',\n",
       " 'man',\n",
       " 'even',\n",
       " 'eens',\n",
       " 'terug',\n",
       " 'komt',\n",
       " 'misschien',\n",
       " 'laten',\n",
       " 'niets',\n",
       " 'zei',\n",
       " 'iemand',\n",
       " 'hou',\n",
       " 'oké',\n",
       " 'veel',\n",
       " 'komen',\n",
       " 'weer',\n",
       " 'tot',\n",
       " 'zeg',\n",
       " 'uw',\n",
       " 'mensen',\n",
       " 'toen',\n",
       " 'zeggen',\n",
       " 'worden',\n",
       " 'onze',\n",
       " 'zit',\n",
       " \"z'n\",\n",
       " 'mag',\n",
       " 'kijk',\n",
       " 'leven',\n",
       " 'heel',\n",
       " 'nodig',\n",
       " 'tegen',\n",
       " 'wordt',\n",
       " 'gewoon',\n",
       " 'twee',\n",
       " 'net',\n",
       " 'dood',\n",
       " 'altijd',\n",
       " 'weten',\n",
       " 'wij',\n",
       " 'maken',\n",
       " 'tijd',\n",
       " 'gedaan',\n",
       " 'af',\n",
       " 'omdat',\n",
       " 'geef',\n",
       " 'zeker',\n",
       " 'zie',\n",
       " 'dag',\n",
       " 'doet',\n",
       " 'wacht',\n",
       " 'niks',\n",
       " 'kunt',\n",
       " 'vrouw',\n",
       " 'huis',\n",
       " 'allemaal',\n",
       " 'vader',\n",
       " 'geld',\n",
       " 'dacht',\n",
       " 'anders',\n",
       " 'wilt',\n",
       " 'dank',\n",
       " 'jaar',\n",
       " 'hun',\n",
       " 'zij',\n",
       " 'willen',\n",
       " 'erg',\n",
       " 'zitten',\n",
       " 'hé',\n",
       " 'keer',\n",
       " 'jouw',\n",
       " 'zoals',\n",
       " 'wilde',\n",
       " 'niemand',\n",
       " 'iedereen',\n",
       " 'zich',\n",
       " 'gezien',\n",
       " 'vind',\n",
       " 'beter',\n",
       " 'werk',\n",
       " 'binnen',\n",
       " 'bedankt',\n",
       " 'spijt',\n",
       " 'vast',\n",
       " 'neem',\n",
       " 'andere',\n",
       " 'staat',\n",
       " 'moeder',\n",
       " 'zullen',\n",
       " 'waren',\n",
       " 'maak',\n",
       " 'praten',\n",
       " 'één',\n",
       " \"'m\",\n",
       " 'kon',\n",
       " 'mooi',\n",
       " 'hele',\n",
       " 'genoeg',\n",
       " 'vinden',\n",
       " 'lang',\n",
       " 'leuk',\n",
       " 'wist',\n",
       " 'na',\n",
       " 'graag',\n",
       " 'toe',\n",
       " 'helpen',\n",
       " 'zegt',\n",
       " 'elkaar',\n",
       " 'ziet',\n",
       " 'blijf',\n",
       " 'natuurlijk',\n",
       " 'god',\n",
       " 'klaar',\n",
       " 'bedoel',\n",
       " 'hallo',\n",
       " 'sorry',\n",
       " 'helemaal',\n",
       " 'maakt',\n",
       " 'gek',\n",
       " 'alle',\n",
       " 'luister',\n",
       " 'drie',\n",
       " 'geweest',\n",
       " 'meneer',\n",
       " 'werd',\n",
       " 'blijven',\n",
       " 'zonder',\n",
       " 'hoor',\n",
       " 'dingen',\n",
       " 'aan_het',\n",
       " 'ging',\n",
       " 'houden',\n",
       " 'alsjeblieft',\n",
       " 'krijgen',\n",
       " 'kijken',\n",
       " 'vriend',\n",
       " 'grote',\n",
       " 'idee',\n",
       " 'kwam',\n",
       " 'bang',\n",
       " 'steeds',\n",
       " 'geven',\n",
       " 'kinderen',\n",
       " 'achter',\n",
       " 'eerste',\n",
       " 'naam',\n",
       " \"zo'n\",\n",
       " 'vertellen',\n",
       " 'goede',\n",
       " 'ooit',\n",
       " 'moest',\n",
       " 'snel',\n",
       " 'onder',\n",
       " 'zag',\n",
       " 'wanneer',\n",
       " 'auto',\n",
       " 'ie',\n",
       " 'beetje',\n",
       " 'eten',\n",
       " 'vragen',\n",
       " 'gebeurd',\n",
       " 'zelf',\n",
       " 'vraag',\n",
       " 'jongen',\n",
       " 'paar',\n",
       " 'ken',\n",
       " 'deed',\n",
       " 'kun',\n",
       " 'o',\n",
       " 'lijkt',\n",
       " 'verdomme',\n",
       " 'morgen',\n",
       " 'staan',\n",
       " 'zorgen',\n",
       " 'want',\n",
       " 'nieuwe',\n",
       " 'gezegd',\n",
       " 'thuis',\n",
       " 'laatste',\n",
       " 'heen',\n",
       " 'geloof',\n",
       " 'geweldig',\n",
       " 'wereld',\n",
       " 'nemen',\n",
       " 'hadden',\n",
       " 'zelfs',\n",
       " 'jongens',\n",
       " 'meisje',\n",
       " 'mannen',\n",
       " 'denken',\n",
       " 'enige',\n",
       " 'vertel',\n",
       " 'denkt',\n",
       " 'krijg',\n",
       " 'samen',\n",
       " 'vandaag',\n",
       " 'hoop',\n",
       " 'halen',\n",
       " 'buiten',\n",
       " 'wou',\n",
       " 'eerst',\n",
       " 'eigen',\n",
       " 'rustig',\n",
       " 'horen',\n",
       " 'soms',\n",
       " 'uur',\n",
       " 'zoon',\n",
       " 'politie',\n",
       " 'houdt',\n",
       " 'probleem',\n",
       " 'zat',\n",
       " 'heet',\n",
       " 'gevonden',\n",
       " 'open',\n",
       " 'vermoord',\n",
       " 'bijna',\n",
       " 'kind',\n",
       " 'vrienden',\n",
       " 'geeft',\n",
       " 'zouden',\n",
       " 'gelijk',\n",
       " 'geleden',\n",
       " 'hen',\n",
       " 'gebeurt',\n",
       " 'oh',\n",
       " 'elke',\n",
       " 'pas',\n",
       " 'krijgt',\n",
       " 'precies',\n",
       " 'begrijp',\n",
       " 'wachten',\n",
       " 'verder',\n",
       " 'hè',\n",
       " 'voel',\n",
       " 'vanavond',\n",
       " 'gehad',\n",
       " 'zet',\n",
       " 'alsof',\n",
       " 'pak',\n",
       " 'kant',\n",
       " 'eigenlijk',\n",
       " 'bel',\n",
       " 'volgens',\n",
       " 'werken',\n",
       " 'best',\n",
       " 'beste',\n",
       " 'daarom',\n",
       " 'familie',\n",
       " 'haal',\n",
       " 'stop',\n",
       " 'vindt',\n",
       " 'vroeg',\n",
       " 'gehoord',\n",
       " 'probeer',\n",
       " 'mr',\n",
       " 'dagen',\n",
       " 'eruit',\n",
       " 'volgende',\n",
       " 'word',\n",
       " 'hoeveel',\n",
       " 'ding',\n",
       " 'schiet',\n",
       " 'vijf',\n",
       " 'spreken',\n",
       " 'help',\n",
       " 'gemaakt',\n",
       " 'blij',\n",
       " 'ligt',\n",
       " 'prima',\n",
       " 'lekker',\n",
       " 'kamer',\n",
       " 'hoofd',\n",
       " 'oude',\n",
       " 'zoeken',\n",
       " 'stad',\n",
       " 'ben.',\n",
       " 'werkt',\n",
       " 'vond',\n",
       " 'geloven',\n",
       " 'kleine',\n",
       " 'slecht',\n",
       " 'pijn',\n",
       " 'jezelf',\n",
       " 'blijft',\n",
       " 'kans',\n",
       " 'in_orde',\n",
       " 'schat',\n",
       " 'ogen',\n",
       " 'niet_eens',\n",
       " 'welke',\n",
       " 'verteld',\n",
       " 'manier',\n",
       " 'ergens',\n",
       " 'mooie',\n",
       " 'moment',\n",
       " 'kent',\n",
       " 'breng',\n",
       " 'tussen',\n",
       " 'brengen',\n",
       " \"'s\",\n",
       " 'spelen',\n",
       " 'deur',\n",
       " 'school',\n",
       " 'minuten',\n",
       " 'vrouwen',\n",
       " 'broer',\n",
       " 'boven',\n",
       " 'water',\n",
       " 'dokter',\n",
       " 'land',\n",
       " 'aan_de_hand',\n",
       " 'vier',\n",
       " 'praat',\n",
       " 'bed',\n",
       " 'hulp',\n",
       " 'zaak',\n",
       " 'klopt',\n",
       " 'groot',\n",
       " 'juist',\n",
       " 'week',\n",
       " 'dollar',\n",
       " 'sta',\n",
       " 'zoveel',\n",
       " 'wees',\n",
       " 'vrij',\n",
       " 'problemen',\n",
       " 'later',\n",
       " 'vergeten',\n",
       " 'vooruit',\n",
       " 'kop',\n",
       " 'bellen',\n",
       " 'hoeft',\n",
       " 'echte',\n",
       " 'proberen',\n",
       " 'betekent',\n",
       " 'papa',\n",
       " 'soort',\n",
       " 'lopen',\n",
       " 'snap',\n",
       " 'mis',\n",
       " 'zult',\n",
       " 'dochter',\n",
       " 'zorg',\n",
       " 'meteen',\n",
       " 'doden',\n",
       " 'ervan',\n",
       " 'beginnen',\n",
       " 'gebruiken',\n",
       " 'stel',\n",
       " 'handen',\n",
       " 'mevrouw',\n",
       " 'plaats',\n",
       " 'leren',\n",
       " 'klootzak',\n",
       " 'alstublieft',\n",
       " 'slapen',\n",
       " 'zoiets',\n",
       " 'liefde',\n",
       " 'vol',\n",
       " 'moeilijk',\n",
       " 'druk',\n",
       " 'tien',\n",
       " 'mama',\n",
       " 'voorbij',\n",
       " 'gekomen',\n",
       " 'gelukkig',\n",
       " 'nacht',\n",
       " 'verhaal',\n",
       " 'nummer',\n",
       " 'zodat',\n",
       " 'wakker',\n",
       " 'mogen',\n",
       " 'hand',\n",
       " 'zes',\n",
       " 'vergeet',\n",
       " 'zoek',\n",
       " 'gebeuren',\n",
       " 'sinds',\n",
       " 'fijn',\n",
       " 'voordat',\n",
       " 'hoort',\n",
       " 'bezig',\n",
       " 'hart',\n",
       " 'klein',\n",
       " 'vermoorden',\n",
       " 'liggen',\n",
       " 'stoppen',\n",
       " 'straks',\n",
       " 'hetzelfde',\n",
       " 'drinken',\n",
       " 'begin',\n",
       " 'aardig',\n",
       " 'gaf',\n",
       " 'eerder',\n",
       " 'ander',\n",
       " 'vent',\n",
       " 'waarheid',\n",
       " 'neer',\n",
       " 'beneden',\n",
       " 'agent',\n",
       " 'zaken',\n",
       " 'bloed',\n",
       " 'los',\n",
       " 'gezicht',\n",
       " 'oud',\n",
       " 'dicht',\n",
       " 'wat_voor',\n",
       " 'hoorde',\n",
       " 'vallen',\n",
       " 'avond',\n",
       " 'eraan',\n",
       " 'vaak',\n",
       " 'oorlog',\n",
       " 'nieuws',\n",
       " 'hoi',\n",
       " 'schuld',\n",
       " 'plek',\n",
       " 'kennen',\n",
       " 'begrepen',\n",
       " 'stuk',\n",
       " 'sterven',\n",
       " 'rest',\n",
       " 'buurt',\n",
       " 'veilig',\n",
       " 'mogelijk',\n",
       " 'film',\n",
       " 'maanden',\n",
       " 'vriendin',\n",
       " 'redden',\n",
       " 'terwijl',\n",
       " 'zin',\n",
       " 'rond',\n",
       " 'ouders',\n",
       " 'eerlijk',\n",
       " 'inderdaad',\n",
       " 'liever',\n",
       " 'overal',\n",
       " 'anderen',\n",
       " 'duidelijk',\n",
       " 'langs',\n",
       " 'belangrijk',\n",
       " 'kreeg',\n",
       " 'liet',\n",
       " 'hond',\n",
       " 'voelt',\n",
       " 'waarschijnlijk',\n",
       " 'heren',\n",
       " 'jaren',\n",
       " 'stond',\n",
       " 'baas',\n",
       " 'geluk',\n",
       " 'mond',\n",
       " 'vandaan',\n",
       " 'fout',\n",
       " 'klinkt',\n",
       " 'per',\n",
       " 'reden',\n",
       " 'ermee',\n",
       " 'mezelf',\n",
       " 'betalen',\n",
       " 'welkom',\n",
       " 'stil',\n",
       " 'hard',\n",
       " 'recht',\n",
       " 'prachtig',\n",
       " 'baan',\n",
       " 'houd',\n",
       " 'erop',\n",
       " 'kwaad',\n",
       " 'kapitein',\n",
       " 'telefoon',\n",
       " 'mam',\n",
       " 'pa',\n",
       " 'neemt',\n",
       " 'gegeven',\n",
       " 'al.',\n",
       " 'zetten',\n",
       " 'valt',\n",
       " 'baby',\n",
       " 'haat',\n",
       " 'dezelfde',\n",
       " 'boek',\n",
       " 'hield',\n",
       " 'trouwen',\n",
       " 'eén',\n",
       " 'rijden',\n",
       " 'zeer',\n",
       " 'hoezo',\n",
       " 'weken',\n",
       " 'lichaam',\n",
       " 'geworden',\n",
       " 'voorzichtig',\n",
       " 'jack',\n",
       " 'kwijt',\n",
       " 'daarna',\n",
       " 'nergens',\n",
       " 'erin',\n",
       " 'mens',\n",
       " 'vanaf',\n",
       " 'plan',\n",
       " 'elk',\n",
       " 'deel',\n",
       " 'moord',\n",
       " 'noemen',\n",
       " 'vertrouwen',\n",
       " 'wapen',\n",
       " 'pakken',\n",
       " 'antwoord',\n",
       " 'kerel',\n",
       " 'schatje',\n",
       " 'niet_alleen',\n",
       " 'koning',\n",
       " 'gebeld',\n",
       " 'ontmoet',\n",
       " 'jezus',\n",
       " 'geval',\n",
       " 'loopt',\n",
       " 'tijdens',\n",
       " 'nogal',\n",
       " 'meer_dan',\n",
       " 'allebei',\n",
       " 'lieverd',\n",
       " 'getrouwd',\n",
       " 'koffie',\n",
       " 'meisjes',\n",
       " 'naartoe',\n",
       " 'veranderen',\n",
       " 'miljoen',\n",
       " 'dr.',\n",
       " 'schieten',\n",
       " 'dames',\n",
       " 'gisteren',\n",
       " 'ver',\n",
       " 'zus',\n",
       " 'sir',\n",
       " 'kopen',\n",
       " 'erbij',\n",
       " 'maakte',\n",
       " 'tweede',\n",
       " 'ziek',\n",
       " 'woord',\n",
       " 'president',\n",
       " 'leg',\n",
       " 'grappig',\n",
       " 'ziens',\n",
       " 'gevoel',\n",
       " 'gebruikt',\n",
       " 'verloren',\n",
       " 'ontmoeten',\n",
       " 'vreemd',\n",
       " 'stap',\n",
       " 'vechten',\n",
       " 'trek',\n",
       " 'plezier',\n",
       " 'daarmee',\n",
       " 't.',\n",
       " 'vroeger',\n",
       " 'kantoor',\n",
       " 'goeie',\n",
       " 'begint',\n",
       " 'fantastisch',\n",
       " 'ervoor',\n",
       " 'dan_ook',\n",
       " 'verwacht',\n",
       " 'zomaar',\n",
       " 'meen',\n",
       " 'gegaan',\n",
       " 'bedoelt',\n",
       " 'pardon',\n",
       " 'minder',\n",
       " '1',\n",
       " 'normaal',\n",
       " 'vertelde',\n",
       " 'nieuw',\n",
       " 'zichzelf',\n",
       " 't',\n",
       " 'slechte',\n",
       " 'foto',\n",
       " 'pap',\n",
       " 'leeft',\n",
       " 'loop',\n",
       " 'voelen',\n",
       " 'john',\n",
       " 'idioot',\n",
       " 'hemel',\n",
       " 'winnen',\n",
       " 'lk',\n",
       " 'eindelijk',\n",
       " 'nam',\n",
       " 'eet',\n",
       " 'men',\n",
       " 'stuur',\n",
       " 'mrs',\n",
       " 'verkeerd',\n",
       " 'val',\n",
       " 'in_deze',\n",
       " 'schip',\n",
       " 'ls',\n",
       " 'enkele',\n",
       " 'meid',\n",
       " 'team',\n",
       " '2',\n",
       " 'gevraagd',\n",
       " 'lief',\n",
       " 'gesproken',\n",
       " 'waard',\n",
       " 'enkel',\n",
       " 'beloof',\n",
       " 'woorden',\n",
       " 'einde',\n",
       " 'slaap',\n",
       " 'jawel',\n",
       " 'hierheen',\n",
       " 'new_york',\n",
       " 'vreselijk',\n",
       " 'met_rust',\n",
       " 'begrijpen',\n",
       " 'slim',\n",
       " 'trots',\n",
       " 'de_tijd',\n",
       " 'onzin',\n",
       " 'acht',\n",
       " 'gang',\n",
       " 'weinig',\n",
       " 'spullen',\n",
       " 'gekregen',\n",
       " 'grond',\n",
       " 'ziekenhuis',\n",
       " 'onderzoek',\n",
       " 'wapens',\n",
       " 'droom',\n",
       " 'oom',\n",
       " 'herinner',\n",
       " 'brengt',\n",
       " 'nietwaar',\n",
       " 'leger',\n",
       " 'let',\n",
       " 'lezen',\n",
       " 'veranderd',\n",
       " 'wonen',\n",
       " 'muziek',\n",
       " 'verliefd',\n",
       " 'omhoog',\n",
       " 'begon',\n",
       " 'stellen',\n",
       " 'boos',\n",
       " 'of_zo',\n",
       " 'gebruik',\n",
       " 'noem',\n",
       " 'konden',\n",
       " 'eentje',\n",
       " 'gevangenis',\n",
       " 'kleren',\n",
       " 'half',\n",
       " 'frank',\n",
       " 'werden',\n",
       " 'informatie',\n",
       " 'stomme',\n",
       " 'zwarte',\n",
       " 'perfect',\n",
       " 'langer',\n",
       " 'heer',\n",
       " 'stom',\n",
       " 'succes',\n",
       " 'licht',\n",
       " 'zeven',\n",
       " 'hoef',\n",
       " 'toekomst',\n",
       " 'makkelijk',\n",
       " 'gingen',\n",
       " 'vraagt',\n",
       " 'mocht',\n",
       " 'dansen',\n",
       " 'advocaat',\n",
       " 'lukt',\n",
       " 'pistool',\n",
       " 'opnieuw',\n",
       " 'begrijpt',\n",
       " 'tenminste',\n",
       " 'wilden',\n",
       " 'woont',\n",
       " 'bewijs',\n",
       " 'geheim',\n",
       " '20',\n",
       " 'kwamen',\n",
       " 'verlaten',\n",
       " 'sam',\n",
       " 'ongeluk',\n",
       " 'vertrekken',\n",
       " 'probeerde',\n",
       " 'vuur',\n",
       " 'straat',\n",
       " 'seks',\n",
       " 'aarde',\n",
       " 'behalve',\n",
       " 'charlie',\n",
       " 'luisteren',\n",
       " 'spreek',\n",
       " 'kracht',\n",
       " \"foto's\",\n",
       " 'volgen',\n",
       " 'wegwezen',\n",
       " 'gebeurde',\n",
       " 'goedemorgen',\n",
       " 'feest',\n",
       " 'beschermen',\n",
       " 'afspraak',\n",
       " 'ene',\n",
       " 'erover',\n",
       " 'gestolen',\n",
       " 'zak',\n",
       " 'verliezen',\n",
       " 'kijkt',\n",
       " 'schrijven',\n",
       " 'absoluut',\n",
       " 'afgelopen',\n",
       " 'liefje',\n",
       " 'koud',\n",
       " 'gedood',\n",
       " 'lijken',\n",
       " 'boot',\n",
       " 'genomen',\n",
       " 'leek',\n",
       " 'trouwens',\n",
       " 'sterk',\n",
       " 'spel',\n",
       " 'ieder',\n",
       " '$',\n",
       " 'lieve',\n",
       " 'geest',\n",
       " 'shit',\n",
       " 'gered',\n",
       " 'juiste',\n",
       " 'slaan',\n",
       " 'persoon',\n",
       " 'serieus',\n",
       " 'moordenaar',\n",
       " 'sommige',\n",
       " 'maand',\n",
       " 'helpt',\n",
       " \"da's\",\n",
       " 'schelen',\n",
       " 'probeert',\n",
       " 'naast',\n",
       " 'degene',\n",
       " 'voelde',\n",
       " 'te_pakken',\n",
       " 'bestaat',\n",
       " 'dienst',\n",
       " 'sturen',\n",
       " 'contact',\n",
       " 'honger',\n",
       " 'welk',\n",
       " 'gevaarlijk',\n",
       " 'jammer',\n",
       " '10',\n",
       " 'bank',\n",
       " 'verkeerde',\n",
       " 'jong',\n",
       " 'gevaar',\n",
       " 'verdomde',\n",
       " 'begonnen',\n",
       " 'ongeveer',\n",
       " 'verkopen',\n",
       " 'reis',\n",
       " 'grootste',\n",
       " 'op_zoek',\n",
       " 'lange',\n",
       " 'erger',\n",
       " 'moe',\n",
       " 'vliegtuig',\n",
       " 'bekend',\n",
       " 'vliegen',\n",
       " 'generaal',\n",
       " 'the',\n",
       " 'gedacht',\n",
       " 'arme',\n",
       " 'lucht',\n",
       " 'bewijzen',\n",
       " 'zolang',\n",
       " 'lachen',\n",
       " 'leuke',\n",
       " 'hotel',\n",
       " 'voorstellen',\n",
       " 'geleerd',\n",
       " 'excuseer',\n",
       " 'moesten',\n",
       " 'betaald',\n",
       " 'slechts',\n",
       " 'via',\n",
       " 'rot',\n",
       " 'lag',\n",
       " 'speelt',\n",
       " 'vorige',\n",
       " 'prijs',\n",
       " 'stem',\n",
       " 'vooral',\n",
       " 'schuldig',\n",
       " 'viel',\n",
       " 'lul',\n",
       " 'geboren',\n",
       " 'zodra',\n",
       " 'vertrouw',\n",
       " 'missen',\n",
       " 'raar',\n",
       " 'rij',\n",
       " 'tv',\n",
       " 'iedere',\n",
       " 'vanwege',\n",
       " 'hel',\n",
       " 'macht',\n",
       " 'regels',\n",
       " 'raak',\n",
       " 'paard',\n",
       " 'geraakt',\n",
       " 'tafel',\n",
       " 'kapot',\n",
       " 'sla',\n",
       " 'george',\n",
       " 'eind',\n",
       " 'he',\n",
       " 'drugs',\n",
       " 'raad',\n",
       " 'm.',\n",
       " 'van_plan',\n",
       " 'dragen',\n",
       " 'kende',\n",
       " 'dame',\n",
       " 'gelooft',\n",
       " 'ziel',\n",
       " 'gefeliciteerd',\n",
       " 'geprobeerd',\n",
       " '3',\n",
       " 'trekken',\n",
       " 'amerika',\n",
       " 'werkte',\n",
       " 'kolonel',\n",
       " 'tom',\n",
       " 'zwaar',\n",
       " 'rug',\n",
       " 'gisteravond',\n",
       " 'sleutel',\n",
       " 'bal',\n",
       " 'wet',\n",
       " 'kost',\n",
       " 'duurt',\n",
       " 'huwelijk',\n",
       " 'gezin',\n",
       " 'gebracht',\n",
       " 'kaart',\n",
       " 'raken',\n",
       " 'volg',\n",
       " 'kerk',\n",
       " 'zweer',\n",
       " '5',\n",
       " 'band',\n",
       " 'arm',\n",
       " 'rijk',\n",
       " 'komaan',\n",
       " 'het_beste',\n",
       " 'zul',\n",
       " 'joe',\n",
       " 'belde',\n",
       " 'jonge',\n",
       " 'daarvoor',\n",
       " 'totdat',\n",
       " 'grapje',\n",
       " 'namen',\n",
       " 'tuurlijk',\n",
       " 'dromen',\n",
       " 'wagen',\n",
       " 'dom',\n",
       " 'vertelt',\n",
       " 'geweldige',\n",
       " 'doel',\n",
       " 'regel',\n",
       " 'ruimte',\n",
       " 'stierf',\n",
       " 'tenzij',\n",
       " 'zover',\n",
       " 'ter',\n",
       " 'meter',\n",
       " 'david',\n",
       " 'harry',\n",
       " 'dronken',\n",
       " 'zoekt',\n",
       " 'derde',\n",
       " 'herinneren',\n",
       " 'teken',\n",
       " 'te_weten',\n",
       " 'relatie',\n",
       " 'gedachten',\n",
       " 'rust',\n",
       " 'ouwe',\n",
       " 'gestuurd',\n",
       " 'groep',\n",
       " 'nadat',\n",
       " 'kwalijk',\n",
       " 'eer',\n",
       " 'gemist',\n",
       " 'zeiden',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtlex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from eSpeakNG_IPA.py\n",
    "from eSpeakNG_IPA import get_phonetic_transcriptions_parallel\n",
    "\n",
    "# Get the list of words from your DataFrame\n",
    "words = list(mous_words['Word'])\n",
    "\n",
    "# Call the function to process all words in parallel\n",
    "ipa_transcriptions = get_phonetic_transcriptions_parallel(words, max_workers=8)\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "MOUS_IPA_transcriptions = pd.DataFrame(list(ipa_transcriptions.items()), columns=['Word', 'IPA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import syllabify_ipa_nl\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(syllabify_ipa_nl)\n",
    "\n",
    "# Re-import the specific function\n",
    "from syllabify_ipa_nl import syllabify_ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUS_IPA_transcriptions['Syllables'] = MOUS_IPA_transcriptions['IPA'].apply(lambda x: syllabify_ipa(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set display options to show more rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(MOUS_IPA_transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOUS_IPA_transcriptions.to_csv('/home/neel/Desktop/MOUS_hierarchical-representations/MOUS_IPA_transcriptions.csv', index = False)\n",
    "MOUS_IPA_transcriptions = pd.read_csv('/home/neel/Desktop/MOUS_hierarchical-representations/MOUS_IPA_transcriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IPA</th>\n",
       "      <th>Syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toen</td>\n",
       "      <td>tˈun</td>\n",
       "      <td>tˈun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>dˈi</td>\n",
       "      <td>dˈi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>dˈə</td>\n",
       "      <td>dˈə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barkeeper</td>\n",
       "      <td>bˈɑrkeːpər</td>\n",
       "      <td>bˈɑr - keː - pər</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irritante</td>\n",
       "      <td>ˌɪɾritˈɑntə</td>\n",
       "      <td>ˌɪɾ - ri - tˈɑn - tə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>betalen</td>\n",
       "      <td>bətˈaːlən</td>\n",
       "      <td>bə - tˈaː - lən</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>intens</td>\n",
       "      <td>ˈɪntəns</td>\n",
       "      <td>ˈɪn - təns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>jongeren</td>\n",
       "      <td>jˈɔŋərən</td>\n",
       "      <td>jˈɔŋ - ə - rən</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>plezier</td>\n",
       "      <td>pleːzˈir</td>\n",
       "      <td>pleː - zˈir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>woonplaats</td>\n",
       "      <td>ʋˈoːnplˌaːts</td>\n",
       "      <td>ʋˈoːn - plˌaːts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word           IPA             Syllables\n",
       "0           toen          tˈun                  tˈun\n",
       "1            die           dˈi                   dˈi\n",
       "2             de           dˈə                   dˈə\n",
       "3      barkeeper    bˈɑrkeːpər      bˈɑr - keː - pər\n",
       "4      irritante   ˌɪɾritˈɑntə  ˌɪɾ - ri - tˈɑn - tə\n",
       "...          ...           ...                   ...\n",
       "1937     betalen     bətˈaːlən       bə - tˈaː - lən\n",
       "1938      intens       ˈɪntəns            ˈɪn - təns\n",
       "1939    jongeren      jˈɔŋərən        jˈɔŋ - ə - rən\n",
       "1940     plezier      pleːzˈir           pleː - zˈir\n",
       "1941  woonplaats  ʋˈoːnplˌaːts       ʋˈoːn - plˌaːts\n",
       "\n",
       "[1942 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the resulting DataFrame\n",
    "MOUS_IPA_transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tɔr', 'stˈɑnt', 'ˈɔx', 'ˈaːn', 'pˈɵkəls', 'bˈur', 'hɛr', 'tˌi', 'bˈɔk', 'bˈy', 'sprˈɪŋt', 'stˈoːr', 'zˈɪːrt', 'rˈɪst', 'stˈaː', 'bəhɵlp', 'skœytʲ', 'jˈɔŋ', 'hˈɑns', 'ɪŋ', 'tˈœyɣ', 'vrˈoː', 'ʋˈɑst', 'vˈaːr', 'dˈinst', 'zˈɔ', 'kˈɔ', 'nyʊ', 'krˈaːn', 'ʋˈɪnst', 'zʋˈɪt', 'ʋˌɪt', 'ɣˈu', 'pər', 'kˈis', 'ɣaː', 'hˈɪːr', 'rˈumdh', 'dʋaːl', 'dˈɑx', 'kˌɛɪk', 'pˈɑst', 'ˈɑfsxˌɵt', 'dɪɣ', 'təns', 'ˌɪ', 'pli', 'tənt', 'trˌɛ', 'jənt', 'pˈɑrk', 'ɪː', 'bˌœyt', 'dˈoːpt', 'kən', 'ɣˈut', 'kˌaː', 'krˈeːx', 'stˈɛ', 'bˈɛɪɣ', 'bˈɛrɣ', 'zˈœy', 'ˌɛnt', 'tɛn', 'vˈɛrs', 'zɛn', 'dɛ', 'sˈɪm', 'ktə', 'frˈœy', 'slˈaːɣ', 'knˈi', 'ˈɛɪɣ', 'hˈɪ', 'stˈɔnt', 'əls', 'ʃˌirɵrɣ', 'zˈɔrɣ', 'ʋɛrk', 'pɔr', 'krˈɵlən', 'rˈɑ', 'tərs', 'tˈiːm', 'brˈɔ', 'ʋˌɛx', 'dˈœy', 'spɛl', 'ʋɛx', 'bɑŋ', 'bˈɔs', 'lˈɛɪt', 'ɣədɵl', 'fˈoːn', 'zˈɑ', 'ʒə', 'sxrˈɔk', 'spɔːrt', 'ɵsi', 'sy', 'lənt', 'ˌɔl', 'fˈɪlm', 'ɣəsx', 'kɛst', 'mˌeː', 'ʋˈə', 'ɛtʲ', 'hˈœy', 'zˈɵstər', 'stˈɛr', 'dˈoːd', 'krˈy', 'kˌøːr', 'kaːrt', 'lˈɑst', 'moː', 'slˈeː', 'hˌɑl', 'kˈɛrs', 'stˈɑ', 'ˈɑrts', 'ʋˈeːft', 'tɔ', 'ʋˈɪŋ', 'ˈœyt', 'brˈœyk', 'dˈɛrɣ', 'stɑn', 'trˈoːn', 'trˈœy', 'ɣrˌup', 'ˈaːnɣ', 'krˈɪ', 'snˈɑp', 'ʋɛɪŋ', 'blˈeːm', 'dˈɛf', 'rˌeː', 'ty', 'ˈɛrm', 'kɛn', 'nˈaːkt', 'drˈɔp', 'hˈilp', 'spˈɪts', 'pˈeː', 'tˈɪrt', 'smˈaːk', 'ɔnt', 'mˈust', 'pˈɛt', 'pˈɪ', 'strˈœy', 'mˈɪn', 'mˈaːk', 'lən', 'mˈɑx', 'fəl', 'ˌɔnɣ', 'prˈoː', 'zəɣ', 'dˈɪnz', 'sxˈeː', 'tˈɛnt', 'hˈɛlm', 'skˈɑn', 'vɔːɾ', 'ɔn', 'bənˈɵl', 'tˈeː', 'vrˈaːx', 'ɣˈɪŋ', 'ɑrt', 'smˌɛɪ', 'noː', 'bərs', 'sprˈoːk', 'tˈɵlpən', 'ldɪxt', 'ɑ', 'prɔ', 'klɑ', 'ɣrˈɔnt', 'krˈi', 'kˈuk', 'tˈɔn', 'ɣˈɛlt', 'ɣrˈaː', 'ʋˈɛn', 'tˌɛs', 'nˌaːrs', 'sˈœy', 'ˈɑm', 'dˈut', 'hˈɑlf', 'slˈœy', 'vˈirh', 'nˈɪː', 'dˈɔr', 'klˈɛɪn', 'ʋˈɑx', 'tˌɑrts', 'vˈɔːr', 'mˈɛns', 'kˌɑstʲ', 'vi', 'psɪx', 'vˈɔnt', 'brˈɪ', 'ɣəv', 'kɔnsɵmp', 'dɛstrɵk', 'ˈi', 'vˈɛrf', 'səl', 'ʋˌɔːr', 'kʋˈaːt', 'mˈɪːr', 'rˌeːzɵl', 'rˈeːz', 'jɛkt', 'kˈɑn', 'lˌaː', 'ˈɔns', 'ʋˈɑs', 'pɑ', 'krˈaːx', 'snˈɛl', 'lə', 'blˈɪk', 'hˈɑrt', 'ni', 'ɣˈi', 'zɪ', 'fˌɑ', 'ʋaː', 'ʋˌɛt', 'tə', 'bˈɔt', 'ʋˈeːst', 'lˈis', 'dˈeːl', 'vˌoː', 'vəx', 'bˈɔnd', 'nˈu', 'knˈɵləx', 'stəɣ', 'mɪl', 'tˈɔxt', 'rˈoːs', 'ˌɔ', 'dər', 'rˈɪŋ', 'ˈɪn', 'nˈɪks', 'mˈɔrɣ', 'vlˈoːx', 'mˌu', 'pɪ', 'brˌɛɪt', 'mˈɑ', 'dˈɔrp', 'brˈɑnt', 'stˈɛɪɣ', 'sˈaː', 'oː', 'lˈaː', 'pəɣ', 'pˈin', 'bœyk', 'nˈeːn', 'ˈeːt', 'dɛr', 'lˈɛɪkt', 'mˈə', 'sxˈoːl', 'ɣrˈit', 'vˈɔːrt', 'nən', 'zʋˈɑŋ', 'nˌaːr', 'trɛkh', 'ʋˈɛɪ', 'krˈeːɣ', 'ɣrɛɪs', 'zˈoː', 'blˈaː', 'lɔft', 'lɑŋ', 'lˈɑŋs', 'ʋˈaːrt', 'psˈɪx', 'bəsx', 'rˌɪrt', 'mu', 'trɑk', 'fˈeːst', 'zˈɛld', 'rˈɑn', 'spˈeːl', 'ɣˈɑŋ', 'kli', 'klˈɑn', 'tˈun', 'vrˈeːm', 'hˈɔnt', 'ˈɪːrst', 'stɛl', 'tiɲ', 'dˈin', 'mɑnt', 'zˌuk', 'lˈɑ', 'dˈoːs', 'lˈaːɣ', 'spˈoːr', 'ʋˈɛnt', 'dˈɛn', 'drˈɑxt', 'kɪn', 'kˈɪst', 'lˈaːt', 'klˈɑs', 'nˈeːl', 'lˈɛr', 'ˈɑŋ', 'hˈɛ', 'vˈɑt', 'lˈeːs', 'ˈaːk', 'stˈœy', 'mənt', 'nˈɔx', 'bɔr', 'ʋɛ', 'rˈɵstəɣ', 'ər', 'smˈus', 'stˈɑt', 'loː', 'ˌeːn', 'vˈirt', 'tɛr', 'stˈeːts', 'kˌɔm', 'tˈɔx', 'nˌɪs', 'drˈɵpən', 'bˈɑ', 'sɔl', 'kri', 'knˈœystʲ', 'vˈʌʊ', 'ʋˈɛrkt', 'vˈɑr', 'kˈɑr', 'flˌoːp', 'maː', 'nˈeː', 'blu', 'dˌeːlt', 'krˈœy', 'vɪn', 'ɣlˈɑ', 'plˈɵkjəs', 'ləɣ', 'stəlt', 'bˈɵktə', 'ˈʌʊ', 'ˈɛks', 'ʋˈeːs', 'nˌoː', 'zˈukt', 'plˈeː', 'ɣˈɑns', 'dɪŋ', 'mˈɪs', 'trˈoː', 'ˈɔm', 'təɣ', 'tʋˈeː', 'deː', 'vˈɛ', 'kˈɔn', 'bix', 'ʋˈoː', 'hoː', 'stˈɔrm', 'strˈɑn', 'maːr', 'bˈuk', 'stɪk', 'lˈɑm', 'sxˈɪld', 'ʒəs', 'sˈɛn', 'ˈaːr', 'jˈɑn', 'zˌɪŋ', 'rˈi', 'ɣrˈyw', 'drˌɑx', 'vˈiwt', 'ˈɛŋ', 'mˈɔːrt', 'kʌʊn', 'lˈɔn', 'bɛɪd', 'prˌoː', 'bˈaːz', 'sxoː', 'sprˈɑk', 'mˈaːkt', 'bˈirtʲ', 'sˈeː', 'pənt', 'bˌur', 'vˈɑst', 'pˌoː', 'ˌɛk', 'tˈif', 'zɛt', 'drˈɛɪxt', 'ˈɑfɣ', 'strˈɛŋ', 'sˈy', 'klˈeː', 'lˈɪst', 'krˈɔ', 'lˌɵkraː', 'lˌɛɪ', 'rˈeːɣ', 'spɪŋ', 'dˈeːm', 'hˈeːft', 'tˈɑnts', 'ˈaːh', 'dɑt', 'vˈyr', 'vrˈin', 'nənk', 'ɣlˈɪ', 'xvˌɑl', 'rˈoː', 'lɔp', 'dˈɛr', 'trˈɛ', 'brˈuk', 'nˈi', 'ˈɛl', 'lˈyk', 'pˈu', 'rˌaːn', 'pˈøː', 'bˈøːrs', 'bəz', 'ʋˈɑt', 'ti', 'strˈaːt', 'by', 'ˈits', 'brˈœykt', 'ʋˌɔŋ', 'prˌaːk', 'pˌɪn', 'zʋˈɛr', 'vɔnt', 'slˈɑŋ', 'sˈɪnts', 'ɑst', 'kˈoːɣ', 'bˈaː', 'ɣəɣ', 'dˈœyt', 'vəl', 'dˈøːr', 'ˈeʊ', 'drˈɵmər', 'smˈeːk', 'dˈi', 'nˌy', 'mˈɵfə', 'mˈɑn', 'stˈɪl', 'rˈaːn', 'stˈilt', 'aːs', 'hˈaːl', 'klˈøː', 'brˈœy', 'kˈɔst', 'mˈɑr', 'ɔl', 'pˌaː', 'dˈɛlh', 'ˌɑl', 'tˈoːn', 'nˈit', 'pˈɪː', 'stˈɔr', 'mˈaːr', 'ʋɑxt', 'sxˈɑt', 'lɪxt', 'slˈɛx', 'stˈɑl', 'və', 'nøːt', 'nˈeːm', 'nˈaː', 'kˈoː', 'kˈɛrk', 'zˈu', 'ˈɛɪ', 'kˈaːr', 'prˈœy', 'ˈeː', 'təx', 'bˈɑnts', 'vˈaː', 'ʋˈɛr', 'vɑkɵn', 'krˈeː', 'tˌiːm', 'drˌaːj', 'prˈœyk', 'ˈɔŋ', 'hˈɵlpvər', 'ɔnh', 'zˈin', 'mɛn', 'dˈɔx', 'nˈux', 'ləks', 'mˈɛt', 'ɑn', 'blˈɔn', 'bə', 'vlˈiɣ', 'pˈy', 'spˈɔr', 'kˈɪ', 'sxˈɛr', 'ˈaːns', 'lˈœy', 'əm', 'zaːm', 'drˈɛɪf', 'ə', 'sˈɔɲ', 'ɣˈɛrst', 'zˈɛl', 'sˌɛrt', 'dˌɑm', 'zˈɛɪn', 'tˈoːr', 'tˈaːt', 'dɪskɵ', 'sprˈɪŋ', 'voː', 'mˈoːɣ', 'rəls', 'dˈə', 'hˈɑnt', 'pˈutst', 'smə', 'kʋˈɑm', 'lˌeː', 'drˌeː', 'klˈøːrt', 'zər', 'tˌɑm', 'fˈi', 'ˈyr', 'ˈoːk', 'zˈaː', 'dˈif', 'ʋˈɪr', 'rənt', 'vrɛɪ', 'lˈoːɣ', 'əns', 'bˈʌʊ', 'prɪn', 'kˌist', 'tɔs', 'ʋˈɑn', 'hɑrdh', 'pˈʌʊ', 'fˈʌʊt', 'stˈɔp', 'plˈɑntʲ', 'ˈɑrt', 'lˈɔs', 'drˈeːf', 'pˈɑp', 'knˈɵsə', 'kərt', 'flˈɑ', 'plˈeːɣ', 'jˈœyx', 'fər', 'məs', 'nˌaː', 'lɑr', 'rˈɛɪft', 'rˈøːs', 'pəlt', 'rˈɑnts', 'brˈɑnd', 'hˈaːlt', 'ˈɑnt', 'zi', 'ˈœytɣ', 'vˈeːlt', 'klˈaː', 'vɑ', 'kˈɔɾrɵp', 'mi', 'kənt', 'ɑp', 'lɑnd', 'ˈɔːrt', 'vˈul', 'ʋˈɑxt', 'lˈøːr', 'deːlt', 'tˈik', 'jaː', 'lˈɪːr', 'əd', 'pə', 'drˈaː', 'ɵkəx', 'rɵxˈɛs', 'slˌoː', 'ˈɛrx', 'pˈaːt', 'flˈɛs', 'plˈeːx', 'dˈɛnt', 'fˈoː', 'nˈaːl', 'hˈʌʊt', 'stin', 'lˈeːt', 'ˌɪn', 'kˈaːt', 'stˈɪrt', 'vˈɑstɣ', 'nˈɪr', 'ʃˌaːr', 'tˈɑl', 'stˈɔf', 'zˈə', 'fˌaː', 'prˈɵlən', 'vlˈɔ', 'mər', 'aːɣ', 'nˈɛtʲ', 'brˌaː', 'dˌɔrp', 'bʌʊ', 'ɣrˈoːt', 'sˌi', 'nˈɛt', 'naːr', 'ˈaːjt', 'lˌɔr', 'ˌøː', 'ɣˈaːn', 'pˈɛr', 'nə', 'dəx', 'mˈɪː', 'ˈaː', 'dˈɛɪs', 'sty', 'ˈɑmb', 'lˌaːr', 'ɣrˈaːx', 'rɛk', 'lˌoː', 'dɪxt', 'dˌɪ', 'ˌɪm', 'klˈɛɪ', 'pˈɪtbɵls', 'vˈɔ', 'ˈuf', 'lˈurs', 'lɪnk', 'vˈɪrt', 'rˌɪst', 'mˈɪk', 'ɑd', 'lɛɪ', 'zɑɡ', 'drɛs', 'tˌɑl', 'hˈœys', 'kɛnh', 'jy', 'tˈiːms', 'krˈɛɪɣ', 'kˈɑ', 'dɑm', 'hˈʌʊ', 'pˈi', 'mɛx', 'stˈaːn', 'flˈɪŋ', 'ɣlˌip', 'kɑn', 'zˈɛɪ', 'fərs', 'lˈɑʃ', 'nɑ', 'vlˈeːs', 'bˈyr', 'səm', 'bˈoːm', 'ʋɔːrt', 'sˈɛ', 'zəm', 'rˌɛnt', 'ˈɛx', 'kˈir', 'mɑr', 'dˈɪxt', 'nˌɔst', 'ʋˈeːɣ', 'kɪŋ', 'kˈeːk', 'bˈɛ', 'bˈɑŋ', 'tˈeːn', 'zɪn', 'kɔr', 'ˈɑz', 'kˈɑmp', 'laː', 'rɑh', 'stˈɛnt', 'brˌeː', 'ɣrˈaːf', 'hˈeː', 'vˈurt', 'ˈøːr', 'fˈøːr', 'zikˌɵs', 'tˈɛɾ', 'lˈɛ', 'sɪŋ', 'kərs', 'pˈɑs', 'kɔn', 'vˈeːɣ', 'bˈaːs', 'dˈɔ', 'prˈoːdɵk', 'ən', 'krˈaː', 'poː', 'dˈaːx', 'ʋɛl', 'nəs', 'ˈɑls', 'dəlt', 'plˈaːt', 'lˈoːv', 'tˈœyxt', 'kˈɛɪkt', 'sˈɛs', 'ʋˈɔn', 'zˈɔxt', 'dɪː', 'laːr', 'vrˈuɣ', 'ˈɑf', 'vˈɔːrh', 'zˌɔxt', 'nˈaːk', 'jər', 'smˈɪː', 'ˌɑɾ', 'nɪŋ', 'vɔn', 'hˈaːt', 'rɪ', 'spˈɑ', 'vˈɑn', 'pɪt', 'bˈɛrx', 'vˈaːk', 'ˈɔf', 'brˈœyd', 'sxˈɵldəx', 'droːɣ', 'nˈik', 'jaːxt', 'prˌeː', 'kaː', 'lˈɪxt', 'kʋˈaː', 'nikˌɵs', 'ɣud', 'bˈis', 'slˈɛɪ', 'blˈɪn', 'tˈɑ', 'hˈɛŋk', 'nˈʌʊ', 'fˈɛl', 'ˈaːl', 'drˈɛɪ', 'sˌɛ', 'heː', 'rˈum', 'stˈɛlt', 'ʋˈɛrt', 'ˈɛnt', 'vrˈøːɣ', 'tˌɛɾ', 'lˈir', 'vˈɛnt', 'stˈɛmt', 'lˈɪm', 'ɣrɛ', 'dɑx', 'hˈoːɣ', 'plˌɛ', 'rˈɛt', 'tˈœyn', 'ˈɑr', 'bˈɔʋ', 'dɪ', 'slˈaː', 'rə', 'kraːt', 'hˈɑp', 'dˈɑŋks', 'spɑs', 'rˈɔnt', 'zʋˈɑr', 'drˈoː', 'klˈɛɪntʲ', 'pˌɑ', 'rˌɔnt', 'ʋˈɛ', 'ʋˈoːx', 'trɔm', 'vøːs', 'dˈɔːr', 'slˈɑx', 'kˈaːs', 'ɣrˈup', 'kˈi', 'poːɣ', 'vˈoː', 'doːd', 'sis', 'ˈœy', 'mˈøːr', 'vˌurt', 'ˈɛɪn', 'pˈɛɪn', 'bˌit', 'ɣrˈun', 'ˈɪŋ', 'koːh', 'hˈɑ', 'zˈaːt', 'pɛn', 'blˈut', 'dˈaːr', 'ˌɔrɣ', 'mˈaːn', 'bˈɵrɣərs', 'di', 'hˈɔn', 'ɣˈɵnstəɣ', 'bøːnh', 'pˌɛr', 'zʋˈaː', 'kˈɛndh', 'nˈɔr', 'zˈɪnt', 'kloː', 'sˌɪɲ', 'zˈɑx', 'lyw', 'lˈɔm', 'vɔl', '(en)ɹ', 'drˈaːjt', 'vərɣ', 'ʋaːrsx', 'spaːr', 'mˈu', 'zˈɪːr', 'mˈoː', 'rˈɪr', 'klˈɑnt', 'klˈøːr', 'slˈɪk', 'tər', 'bɑk', 'kˈɪn', 'rɪs', 'bˈøːɣ', 'zˈɪx', 'dʋˈɛrx', 'bˌoː', 'sˈi', 'ˌɑk', 'ju', 'zˈaːl', 'tˈuh', 'tˈɑk', 'trˈaːl', 'loːdɣ', 'prˈɛɪ', 'plɑŋk', 'bˈi', 'trˈɛk', 'əl', 'slˈip', 'vˈɔːrɣ', 'ʃˈik', 'dˌoː', 'zˈir', 'neːtʲ', 'zˈɑk', 'zˈit', 'døːɣ', 'ˈɵtrɛxt', 'pˈɔːrt', 'rən', 'zˈuk', 'nˈoː', 'sˈin', 'zɪŋ', 'lˌɪŋ', 'spˈaːn', 'sɵksˈɛs', 'kˌy', 'ˈɑx', 'ɪ', 'zoː', 'ʋˈɔr', 'stɛ', 'stˌeː', 'prɛ', 'bˌɑ', 'bˈɪː', 'ri', 'ɣrˈu', 'dˈɑn', 'ɪːr', 'krɛŋk', 'bˌʌʊ', 'slˌœy', 'rəx', 'zɛx', 'jˈøː', 'mˈɑnt', 'pɛr', 'tˈɔr', 'ʋˈɪ', 'ʌʊt', 'kˈaː', 'rˈɛɪ', 'fˈɑns', 'lˈoːpt', 'hˈɑt', 'vˈɪŋ', 'lˈeːn', 'sxrˈɛɪ', 'snˈu', 'drˈɵknɔp', 'slˌɑx', 'hˈɛlpt', 'lˈɪ', 'pərs', 'pˈoːtʲ', 'sˌɔ', 'brˈɑxt', 'drˈeː', 'jaːr', 'zˌɑŋ', 'mˈɑrkt', 'hˈœylt', 'ɑrts', 'hˈɑnd', 'ʒˈɪː', 'ˈaːt', 'nˈaːm', 'slɔ', 'li', 'rɑɣ', 'bˈɔɾ', 'krˈɪŋ', 'vˈaːrt', 'ʋˈɛx', 'bˈɑk', 'trˈaː', 'mˈaːɣ', 'hˈɔ', 'sən', 'vˈɛr', 'ˈɔr', 'stˈoː', 'kˈɑnt', 'dˈɛŋkt', 'ˌɑd', 'lˈoːt', 'bˈɔns', 'vrˈeːst', 'kˈɔːrts', 'vrˈʌʊ', 'pvdˈaː', 'blɛ', 'klˈɔwn', 'dˈɔɾ', 'sˈoːn', 'lɪŋ', 'zˌaː', 'stˈɵɣə', 'stən', 'ʋˈɛt', 'jˈoː', 'dɛw', 'lˈɑŋ', 'ˌoː', 'ʋˈɪst', 'ʋˈɪl', 'ˌɑŋ', 'keː', 'dun', 'ˈɛlf', 'jɵlˈi', 'rˈɵstən', 'bərɵx', 'vərsx', 'lˈɵksy', 'jˈaːr', 'rˈɪsp', 'rɛɪn', 'tˈoːm', 'dˈuk', 'dˈøː', 'klˈɔp', 'nɪɣ', 'pˈɔ', 'dˈɛkt', 'drˈoːɣ', 'vˈɔx', 'raːd', 'ploː', 'diɣ', 'ʃˈi', 'tœys', 'snˈoː', 'fɛ', 'tˈaːrt', 'ɣrˈɛɪ', 'tˌeː', 'blɔn', 'bˈɑl', 'lɛtʲ', 'ˈɔːr', 'ˈɪns', 'dɔːrɣ', 'lɪp', 'stʌʊ', 'ɣrˈip', 'ʋˌɑm', 'rˈɔːr', 'vˈaːs', 'mˈɪst', 'jˈɵŋlə', 'mˈɑŋ', 'əɣ', 'jə', 'trˈi', 'əlˌɵxt', 'kˈɔm', 'zˈɛlfs', 'nˈɪk', 'ʋˈɪlt', 'bˈɛɪk', 'ɣrˈɛs', 'lɪː', 'dəɲ', 'mˈɑt', 'zˌɪxt', 'dˈu', 'kˈɑm', 'bu', 'drˈoːm', 'lˈɛɣ', 'vrˈaːɣ', 'kˈɔrt', 'zˈɛlf', 'rˈaː', 'tˈøːr', 'ˌi', 'nɑj', 'ɣrˈi', 'paːɣ', 'stˈur', 'ɣrˈɛɪpt', 'vˈi', 'ɣrˌun', 'ˈɔp', 'pi', 'tərt', 'brˈy', 'pɪŋ', 'dˈɔːrh', 'kˈʌʊt', 'tɪ', 'dˌɑx', 'trɛɪt', 'stˈɑr', 'vəɣ', 'krˈɔŋ', 'ˈɪ', 'pˈɔp', 'kˌoːp', 'knˈɵpəl', 'nˈuɣ', 'jˈə', 'flˈʌʊ', 'bˈɔx', 'ˈaːs', 'kˈøːrt', 'strˈɑf', 'pɔt', 'ˈoːɣ', 'strˈeːl', 'lˌɛxt', 'mˈoːj', 'dəns', 'lˈit', 'spˈøːrh', 'vˈu', 'ɣˈoː', 'ˈɪk', 'pˈir', 'tˌɑk', 'dˈoː', 'tˈɛ', 'frɑn', 'ʋˌɛɪst', 'tˈə', 'doː', 'ˈɛrɣ', 'tˈɪː', 'mˈeːst', 'tu', 'dˈɑ', 'vˈɑ', 'mˈaːl', 'zˈɪn', 'kʌʊ', 'ˌɪɾ', 'tˈoː', 'mˈɔxt', 'bˈaːn', 'rɛɪ', 'rˈɔnd', 'bəɣ', 'nˈɵxtə', 'hˈœysh', 'ˈɑxt', 'rɛɪk', 'mˌɪs', 'tˈi', 'kˌoː', 'məls', 'ɣˈoːj', 'plˈɛɪn', 'ɣˈeːn', 'lɛk', 'brˈɑm', 'mɪ', 'hy', 'bi', 'ʋˈɛɪn', 'lərs', 'vˈɛn', 'lˈɪːrt', 'sˈirs', 'kˈɵnən', 'saː', 'hˈɔːr', 'zə', 'tˈɔt', 'sxˈɛɪt', 'trˈɔ', 'vər', 'rˈɛx', 'spi', 'toːs', 'ɣˈɵldən', 'daː', 'rˈu', 'təl', 'ˌɪrt', 'bry', 'nɛr', 'ɣˈaːt', 'slɑnt', 'sxˈoː', 'spˌɑ', 'ˌɔlt', 'dən', 'brˈi', 'pleːɣ', 'dˈɛɪ', 'rˌɛxt', 'pˈɑn', 'ɣˈoːt', 'dˈaːɣ', 'zərs', 'kˈit', 'kˈɛnt', 'pəx', 'ʋɪːr', 'ˌaːj', 'zʋˈɛm', 'rˈɛɪs', 'lˈi', 'sxˈɵtər', 'bˈaːr', 'nˈɑxt', 'rˈaːd', 'kˈɛt', 'lˌɑnt', 'toː', 'naː', 'rˈɪ', 'kˈɛn', 'plˈaːts', 'stˌyrt', 'ˌeː', 'sˈɵksɛs', 'ɣə', 'mˈut', 'ˈoː', 'ˈɔn', 'nʌʊ', 'ˈɪs', 'frˈɑɣ', 'bəs', 'pˌɑn', 'ˈɪnt', 'vˈeːl', 'mˈɪl', 'kˈoːj', 'ɔ', 'skoːtʃ', 'kəls', 'pəl', 'lˌɑp', 'plˈux', 'pˈaːr', 'tˈɔp', 'ɣrˈɑ', 'stˌɑnt', 'baːrh', 'ʋˈɑr', 'rˈɔ', 'rˌɪk', 'ʒˌur', 'nˌʌʊ', 'vrˈeː', 'hˈeːl', 'ry', 'ʒˈɑst', 'mɛ', 'ˈɛrmh', 'kˈøː', 'prˈɑx', 'ləs', 'ɣəh', 'ʋˈɛts', 'fən', 'ˈɪnsx', 'sɛn', 'nˈiw', 'rɑs', 'lˈifst', 'kəl', 'vɪːr', 'plˈɛk', 'pˌɪː', 'sˌɪː', 'jˈy', 'vrˈaːk', 'kɔm', 'skaː', 'ɣˈɪ', 'py', 'pɛ', 'taːr', 'pˈaːrt', 'zˈɪrt', 'ɣlˈaː', 'drˈɪŋkt', 'blˈeːk', 'slˈœyt', 'dˈaː', 'dˌeː', 'hˈət', 'hˈoː', 'frˈɑŋk', 'dˈy', 'ɣəbˈɵkt', 'zˈɪl', 'ləx', 'hˈɛks', 'bˈɑr', 'nˌɪpt', 'bər', 'hˈoːx', 'ldə', 'nərs', 'vənbˌɵs', 'ˈɪnh', 'jˈɔx', 'frɔn', 'stˈɑn', 'ˈeːn', 'bˈɛlt', 'ˈɔ', 'bəl', 'mˌɪ', 'brˈɛŋ', 'ɣˈoːx', 'mˈy', 'stˈaːt', 'plˈoː', 'blˈeː', 'ˌɛm', 'sˈʌʊs', 'klˈœys', 'ʋˈɪnt', 'pˈɵpi', 'tˌœyn', 'ʋɑ', 'kˌɛrn', 'kɔ', 'ɣˌʌʊd', 'tˈaː', 'jəs', 'lˈaːs', 'pˈɑɲ', 'bˈoːnɵs', 'tˈɛr', 'tˈir', 'ɣˈeːft', 'rˈaːt', 'dˈul', 'ʋˈɛl', 'təv', 'stˈeːlt', 'tin', 'rˈɛs', 'kər', 'mˈaː', 'bˌɑl', 'doːj', 'vɑn', 'sˈɑn', 'lˈiv', 'bˈɪɣ', 'ˌɑx', 'məɣ', 'ˌeːr', 'lˈɑx', 'raː', 'kˈoːtʃ', 'rˈɔt', 'sxˈoːnzɵs', 'bˌɑk', 'mˈaːt', 'nˈiwt', 'rəɣ', 'bən', 'dɔ', 'pˈɛɪp', 'dˈɔn', 'dəɣ', 'jˌi', 'rɪŋ', 'neːl', 'rˌʌʊ', 'i', 'ˌɑ', 'sprˈeː', 'ɵkən', 'klˈɪː', 'spˈeː', 'skɛt', 'bˈit', 'ˈɛn', 'zˈɑt', 'ɪs(nl)', 'rɔl', 'ʋˈoːn', 'ɣˈɑf', 'nˌɪŋ', 'ɣəvˈɵlt', 'bˈɔrɣ', 'tˈɑjs', 'stˈul', 'vaː', 'aː', 'əlt', 'vrˈeːmt', 'tˈɛm', 'dˈɪx', 'drˈiɣ', 'bˈɪ', 'prˈi', 'tˈy', 'ɣˈɛ', 'nər', 'ldɪɣ', 'krˈɑnt', 'bˈøː', 'hˈɑm', 'ɑl', 'lˈɑk', 'sxˈɪl', 'zaːmt', 'ɣiɣ', 'tˈu', 'u', 'təls', 'rˈeːn', 'ˈeːns', 'hˈilt', 'bˈøːrt', 'hˈɑn', 'ˌɔr', 'knˈɑ', 'mə', 'mˈɛn', 'hˌɛɪl', 'dʋˈaː', 'stɔl', 'dˈɑt', 'kɛtʲ', 'kˌɵnstaː', 'kɛɪ', 'kˌɔn', 'plˈɑŋk', 'zˈɑŋ', 'dikˌɵs', 'dəm', 'pˈaː', 'proːdɵk', 'ˌɔːr', 'tˈɛɪ', 'ʋɛɪ', 'rˈɛ', 'tis', 'ksi', 'ɛ', 'bɔn', 'lˈeːft', 'xtə', 'zənt', 'trˈeː', 'tʋˈɛɪɣ', 'ˈoːm', 'bˈeːst', 'tən', 'kˈɔxt', 'bˈu', 'drˈœy', 'jˈoːst', 'ɣˈʌʊt', 'zˈeː', 'rəns', 'stˌɛr', 'brˈoː', 'tˈɛn', 'mɑn', 'bˈɛk', 'lˈɪx', 'sxˈoːn', 'ˈɔnɣ', 'lˈɛɪ', 'ʃaː', 'kˌɛp', 'dəl', 'ˈɪl', 'ʋˈaːr', 'hˈɛɪ', 'dɑŋk', 'kˈɔmt', 'spˈɛɪ', 'hɛ', 'rˈɛn', 'koː', 'slˌux', 'stˈeːl', 'vrˈɛɪ', 'lˈeːɣ', 'hˈɛm', 'kˈɔr', 'vrˈint', 'fˈeːstɣ', 'kəns', 'lˈift', 'mˈuj', 'nəɣ', 'mˈɑxt', 'ˈe', 'soː', 'bˌaː', 'kˈaːn', 'plˈɑ', 'tɛɪt', 'smˈaː', 'ldəɣ', 'dˈeː', 'rˌeːɣ', 'nˌɑ', 'ɪf', 'ʋɑnh', 'lˌoːx', 'strˈɑ', 'tˈɛx', 'zˈɪ', 'zˈɛlsx', 'dˈaːt', 'ʃoː', 'ɑt', 'lˈeː', 'ˈœytsx', 'tˈus', 'lər', 'snˈɛ', 'stɑl', 'stˌɑl', 'rˈɛxt', 'ˈɪndrˌɵk', 'rəlt', 'rˈʌʊ', 'mɪŋ', 'traː', 'sloːs', 'ˈoːn', 'ʋˈix', 'ˈɑfh', 'vərh', 'vˈeː', 'sˈɔms', 'lˈaːtst', 'tɛk', 'stˌɔnt', 'ʋˈɔrt', 'kˈɔk', 'kə', 'nˈɑf', 'bəv', 'dˈɛs', 'nˈits', 'mˈi', 'vˌɔ', 'spˈɑɲ', 'ərs', 'ˈɑ', 'lˈɛxt', 'ʋɑx', 'bˈeː', 'mˈɪ', 'bˈɔl', 'drˈɑŋk', 'pˈɑ', 'vlˈi', 'rˌaː', 'mərs', 'jˈaː', 'bˈœy', 'kløːr', 'rˌɪ', 'rˌɛ', 'eːn', 'hˈɑndsx', 'kˌɔmst', 'fɛr', 'ʋˈɔːrt', 'dˈeːt', 'tˈɑnt', 'fˈɛt', 'krˌi', 'fˈɪr', 'hˌeː', 'sˈeːl', 'rɛ', 'mɑ', 'stˈeː', 'tərˈɵx', 'dɑrts', 'drˈɔŋ', 'pˈɪtʲ', 'zɛ', 'vən', 'tˈɛntʲ', 'ˈɑl', 'riɣ', 'stˈu', 'bɑt', 'baː', 'hˈaːk', 'tˈaːl', 'ˈɪːr', 'seː', 'brˈeːkt', 'lˌaːrs', 'pˈɛst', 'stɔ', 'roːɣ', 'ˌut', 'ndəɣ', 'trˈɔk', 'vrˈaːxt', 'tˈɛl', 'lˈip', 'rɪn', 'ˌɑm', 'blˈɵndər', 'ʒˈɑ', 'brˈaː', 'frˈi', 'blˈu', 'zˈi', 'kˈoːkt', 'kˈoːpt', 'ˌaː', 'drˈi', 'ʃˈɔn', 'bəsxɵl', 'kˈɪd', 'rˈeː', 'mˌɑn', 'pzaː', 'stˈɑɾ', 'pɵblˈik', 'kˈeːs', 'hˈɑŋt', 'bˈɔr', 'spˈeːlt', 'dˈun', 'zˈɛt', 'rˈœy', 'rˈɛnt', 'vlˈur', 'trˌi', 'tʋˈaːlf', 'flˈoːr', 'ɣˈʌʊ', 'nɪ', 'kˈɛ', 'pˈeːt', 'eː', 'plˌaːts', 'sxrˈeʊ', 'pis', 'jˈøːs', 'rˈɛɪk', 'mˈɔːr', 'nis', 'rɑf', 'ˈy', 'slˈɪŋk', 'tərɵx', 'dɪk', 'lˈɑndɣ', 'dˈœyk', 'sxˈyrtʲ', 'hˈaːr', 'slˈɪ', 'nˈir', 'zˈɔl', 'tˈɪp', 'mˈɛɪn', 'tˈyr', 'jˈɑm', 'fə', 'bri', 'brˈif', 'trˈɛɪ', 'zˈɛ', 'pˌy', 'drˈɑŋ', 'bˈɵskrœyt', 'krˌeː', 'ˈɪst', 'mˈɛɪs', 'taː', 'vrˈux', 'zˈɪt', 'ləm', 'lˈɛɪst', 'rˈoːt', 'ɑŋ', 'ɣˈɛk', 'vlˈɵxtə', 'tˌaː', 'tri', 'krə', 'hˈyw', 'ˈɑt', 'vlˈɑk', 'ˈɑk', 'ˌɛɪ', 'hˈɛf', 'tˈɛɪɣ', 'xˌoː', 'dˈyr', 'smɑn', 'bˈœyɣ', 'rˈins', 'bɑn', 'hˈaːx', 'nˈy', 'mˈɛnt', 'nˈɪxtʲ', 'də', 'blˈɛɪ', 'sɪ', 'vrˈʌʊtʲ', 'pleː', 'klˈɔm', 'ˈɪnɣ', 'psi', 'bˈeːt', 'ɣˈeː', 'tʋˈɪn', 'vˈɪr', 'ʋˈeː', 'prˈeː', 'stər', 'pˌɵbli', 'ɣrˈoː', 'tˈɑn', 'ɔntvlˈɵxt', 'hˈaː', 'ˈaːlt', 'dʋˈaːsh', 'sˌɔr', 'bˈɔ', 'paː', 'ˌœys', 'frˈœyt', 'brˌɑxt', 'mən', 'staː', 'lˈoː', 'nˈɛr', 'zˌɪx', 'tɛst', 'trˈu', 'rˈin', 'stˌɛl', 'lˌɑnd', 'vˈis', 'plˈɑnt', 'plˈɛɪ', 'vˈɛx', 'nˈɑm', 'brˈoːt', 'ˈɛ', 'zˈɔrxt', 'zaː', 'rˈɛɪn', 'stˈɪr', 'vˈɔl', 'dˈɪŋ', 'ˌɛn', 'droː', 'rˈɪxt', 'bˈɑnt', 'ɛr', 'ʋˈɪːr', 'tɪŋ', 'dˌi', 'zˈɔn', 'ˈər', 'bəh', 'ˌaːrt', 'ʋˈɪː', 'zˈʌʊ', 'kɑ', 'zˈøːr', 'ʃɑm', 'zən', 'lək', 'lˈøː', 'fˌɔ', 'trˈɪ', 'ˌɔf', 'ˈɪndrɵk', 'stɔr', 'dˈɪ', 'ˌɑxt', 'fˌi', 'dˌaːn', 'vˌi', 'rˌaːrs', 'ˌy', 'dərs', 'trˈʌʊ', 'spˈɔrth', 'spɔp', 'nˈaːr', 'bˈeːtɣ', 'kəŋ', 'tˈɛɪt', 'vˈil', 'zˈɛs', 'bˈoːs', 'baːr', 'mˌoː', 'hˈir', 'sə', 'ˈoːr', 'trˈɑt', 'lˈeːst', 'ˌyr', 'vˈɑlt', 'kˈɑst', 'bˈœykh', 'rˌaːs', 'flˈaːt', 'tˈɑŋk', 'ʋˈeːk', 'ˈɛɪk', 'tˈʌʊ', 'hˈoːft', 'si', 'vˌɑ', 'lɛ', 'drˈux', 'ˌʌʊt', 'ˌɛl', 'stˈyr', 'kənv', 'ɣˈɑ', 'nˈɛ', 'naːm', 'zˈɵsjəs', 'zoːj', 'slˈaːv', 'roː', 'stɔf', 'ʋˈaː', 'mˈɛl', 'ʋˈɛrk', 'drˈɵkə', 'bˈaːst', 'ˈɑn', 'mˈeː', 'kaːr', 'vɪŋ', 'flˈɛ', 'blˈʌʊ', 'brˈur', 'dɪn', 'ɣəhɵl', 'sər', 'bɛɪ', 'ʋˈɔ', 'ʃˌaː', 'əs', 'pˈɑk', 'nˈeːɣ', 'nˌeː', 'tɑkt', 'hˈœyl', 'vɑŋt', 'lˈɛs', 'brˈeː', 'krˈɛɪxt', 'sˈɛnt', 'bˈɛɪ', 'mˈaːnt', 'hˈɛn', 'tənd', 'ɛɪt', 'kˌɑn', 'prˌeːs', 'bɑl', 'brˈurtʲ', 'staːn', 'brˈœyt', 'bˈoː', 'pɑr', 'pən', 'peː', 'rˈɛk', 'dˈɑr', 'ɣru', 'ldəx', 'ʃɔnsh', 'ˈɔpɣ', 'dˈoːr', 'jˈɪː', 'əlɵ', 'lˈɪrt', 'trˈɔts', 'nəx', 'lˈin', 'tˈeːɣ', 'mˌɛrkt', 'mɪz', 'sxrˈɪ', 'krˈɛɪx', 'ʋˈɑŋɣ', 'zˈɪŋ', 'lˈɛː', 'rˈɪx', 'ɛɪndh', 'dərt', 'bɛrt', 'kˈɛɪ', 'try', 'sˈɛr', 'vˈɔː', 'pɑn', 'ɣlˈɪpt', 'tərh', 'ɣəlɵ', 'kʋˈɛɪt', 'dˈɪt', 'proː', 'stə', 'kˈɪːr', 'klˈɔwns', 'jən', 'dˈɑxt', 'sɛr']\n"
     ]
    }
   ],
   "source": [
    "# Split each word's syllables into a list, handling non-string values\n",
    "syllables_list = MOUS_IPA_transcriptions['Syllables'].apply(lambda x: x.split(' - ') if isinstance(x, str) else []).tolist()\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_syllables = [syllable for sublist in syllables_list for syllable in sublist]\n",
    "\n",
    "# Get unique syllables\n",
    "unique_syllables = list(set(flattened_syllables))\n",
    "\n",
    "print(unique_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>CDlow</th>\n",
       "      <th>FREQlemma</th>\n",
       "      <th>SUBTLEXWF</th>\n",
       "      <th>Zipf</th>\n",
       "      <th>SUBTLEXCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "      <th>dominant.pos</th>\n",
       "      <th>dominant.pos.freq</th>\n",
       "      <th>dominant.pos.lemma</th>\n",
       "      <th>dominant.pos.lemma.freq</th>\n",
       "      <th>all.pos</th>\n",
       "      <th>all.pos.freq</th>\n",
       "      <th>all.pos.lemma.freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ik</td>\n",
       "      <td>1744062</td>\n",
       "      <td>8054</td>\n",
       "      <td>778704</td>\n",
       "      <td>3125</td>\n",
       "      <td>1744527</td>\n",
       "      <td>39883.0334</td>\n",
       "      <td>7.597064</td>\n",
       "      <td>99.8017</td>\n",
       "      <td>3.9061</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1743609</td>\n",
       "      <td>ik</td>\n",
       "      <td>1743944</td>\n",
       "      <td>.VNW.SPEC.N.VZ.</td>\n",
       "      <td>.1743609.448.4.1.</td>\n",
       "      <td>.1743944.448.134.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>1600888</td>\n",
       "      <td>8060</td>\n",
       "      <td>1315051</td>\n",
       "      <td>6535</td>\n",
       "      <td>1600923</td>\n",
       "      <td>36608.9449</td>\n",
       "      <td>7.559864</td>\n",
       "      <td>99.8761</td>\n",
       "      <td>3.9064</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1600798</td>\n",
       "      <td>je</td>\n",
       "      <td>1600798</td>\n",
       "      <td>.VNW.SPEC.N.BW.LID.</td>\n",
       "      <td>.1600798.72.15.2.1.</td>\n",
       "      <td>.1600798.72.50.2.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het</td>\n",
       "      <td>1068396</td>\n",
       "      <td>8066</td>\n",
       "      <td>780771</td>\n",
       "      <td>5578</td>\n",
       "      <td>1913811</td>\n",
       "      <td>24431.9717</td>\n",
       "      <td>7.384235</td>\n",
       "      <td>99.9504</td>\n",
       "      <td>3.9067</td>\n",
       "      <td>VNW</td>\n",
       "      <td>735390</td>\n",
       "      <td>het</td>\n",
       "      <td>735395</td>\n",
       "      <td>.VNW.LID.SPEC.WW.N.</td>\n",
       "      <td>.735390.332929.53.22.2.</td>\n",
       "      <td>.735395.332929.53.845403.31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>1061177</td>\n",
       "      <td>8070</td>\n",
       "      <td>903872</td>\n",
       "      <td>6512</td>\n",
       "      <td>1063827</td>\n",
       "      <td>24266.8883</td>\n",
       "      <td>7.381291</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.9069</td>\n",
       "      <td>LID</td>\n",
       "      <td>1060098</td>\n",
       "      <td>de</td>\n",
       "      <td>1062748</td>\n",
       "      <td>.LID.VNW.SPEC.VZ.</td>\n",
       "      <td>.1060098.806.272.1.</td>\n",
       "      <td>.1062748.806.272.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dat</td>\n",
       "      <td>965424</td>\n",
       "      <td>8063</td>\n",
       "      <td>715570</td>\n",
       "      <td>6107</td>\n",
       "      <td>965431</td>\n",
       "      <td>22077.2184</td>\n",
       "      <td>7.340221</td>\n",
       "      <td>99.9133</td>\n",
       "      <td>3.9066</td>\n",
       "      <td>VNW</td>\n",
       "      <td>532576</td>\n",
       "      <td>dat</td>\n",
       "      <td>532576</td>\n",
       "      <td>.VNW.VG.SPEC.N.WW.</td>\n",
       "      <td>.532576.432794.51.2.1.</td>\n",
       "      <td>.532576.432794.51.9.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437498</th>\n",
       "      <td>&amp;_blake</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_blake</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437499</th>\n",
       "      <td>&amp;_barbie</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_barbie</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437500</th>\n",
       "      <td>&amp;_bake_pizza</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_bake_pizza</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437501</th>\n",
       "      <td>&amp;_bach</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_bach</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437502</th>\n",
       "      <td>&amp;_atlantic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;_atlantic</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437503 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  FREQcount  CDcount  FREQlow  CDlow  FREQlemma  \\\n",
       "0                 ik    1744062     8054   778704   3125    1744527   \n",
       "1                 je    1600888     8060  1315051   6535    1600923   \n",
       "2                het    1068396     8066   780771   5578    1913811   \n",
       "3                 de    1061177     8070   903872   6512    1063827   \n",
       "4                dat     965424     8063   715570   6107     965431   \n",
       "...              ...        ...      ...      ...    ...        ...   \n",
       "437498       &_blake          1        1        1      1          1   \n",
       "437499      &_barbie          1        1        1      1          1   \n",
       "437500  &_bake_pizza          1        1        1      1          1   \n",
       "437501        &_bach          1        1        1      1          1   \n",
       "437502    &_atlantic          1        1        1      1          1   \n",
       "\n",
       "         SUBTLEXWF      Zipf  SUBTLEXCD  Lg10CD dominant.pos  \\\n",
       "0       39883.0334  7.597064    99.8017  3.9061          VNW   \n",
       "1       36608.9449  7.559864    99.8761  3.9064          VNW   \n",
       "2       24431.9717  7.384235    99.9504  3.9067          VNW   \n",
       "3       24266.8883  7.381291   100.0000  3.9069          LID   \n",
       "4       22077.2184  7.340221    99.9133  3.9066          VNW   \n",
       "...            ...       ...        ...     ...          ...   \n",
       "437498      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437499      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437500      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437501      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "437502      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "\n",
       "        dominant.pos.freq dominant.pos.lemma  dominant.pos.lemma.freq  \\\n",
       "0                 1743609                 ik                  1743944   \n",
       "1                 1600798                 je                  1600798   \n",
       "2                  735390                het                   735395   \n",
       "3                 1060098                 de                  1062748   \n",
       "4                  532576                dat                   532576   \n",
       "...                   ...                ...                      ...   \n",
       "437498                  1            &_blake                        1   \n",
       "437499                  1           &_barbie                        1   \n",
       "437500                  1       &_bake_pizza                        1   \n",
       "437501                  1             &_bach                        1   \n",
       "437502                  1         &_atlantic                        1   \n",
       "\n",
       "                    all.pos             all.pos.freq  \\\n",
       "0           .VNW.SPEC.N.VZ.        .1743609.448.4.1.   \n",
       "1       .VNW.SPEC.N.BW.LID.      .1600798.72.15.2.1.   \n",
       "2       .VNW.LID.SPEC.WW.N.  .735390.332929.53.22.2.   \n",
       "3         .LID.VNW.SPEC.VZ.      .1060098.806.272.1.   \n",
       "4        .VNW.VG.SPEC.N.WW.   .532576.432794.51.2.1.   \n",
       "...                     ...                      ...   \n",
       "437498               .SPEC.                      .1.   \n",
       "437499               .SPEC.                      .1.   \n",
       "437500               .SPEC.                      .1.   \n",
       "437501               .SPEC.                      .1.   \n",
       "437502               .SPEC.                      .1.   \n",
       "\n",
       "                  all.pos.lemma.freq  \n",
       "0                .1743944.448.134.1.  \n",
       "1                .1600798.72.50.2.1.  \n",
       "2       .735395.332929.53.845403.31.  \n",
       "3                .1062748.806.272.1.  \n",
       "4             .532576.432794.51.9.1.  \n",
       "...                              ...  \n",
       "437498                           .1.  \n",
       "437499                           .1.  \n",
       "437500                           .1.  \n",
       "437501                           .1.  \n",
       "437502                           .1.  \n",
       "\n",
       "[437503 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>CDlow</th>\n",
       "      <th>FREQlemma</th>\n",
       "      <th>SUBTLEXWF</th>\n",
       "      <th>Zipf</th>\n",
       "      <th>SUBTLEXCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "      <th>dominant.pos</th>\n",
       "      <th>dominant.pos.freq</th>\n",
       "      <th>dominant.pos.lemma</th>\n",
       "      <th>dominant.pos.lemma.freq</th>\n",
       "      <th>all.pos</th>\n",
       "      <th>all.pos.freq</th>\n",
       "      <th>all.pos.lemma.freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ik</td>\n",
       "      <td>1744062</td>\n",
       "      <td>8054</td>\n",
       "      <td>778704</td>\n",
       "      <td>3125</td>\n",
       "      <td>1744527</td>\n",
       "      <td>39883.0334</td>\n",
       "      <td>7.597064</td>\n",
       "      <td>99.8017</td>\n",
       "      <td>3.9061</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1743609</td>\n",
       "      <td>ik</td>\n",
       "      <td>1743944</td>\n",
       "      <td>.VNW.SPEC.N.VZ.</td>\n",
       "      <td>.1743609.448.4.1.</td>\n",
       "      <td>.1743944.448.134.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>1600888</td>\n",
       "      <td>8060</td>\n",
       "      <td>1315051</td>\n",
       "      <td>6535</td>\n",
       "      <td>1600923</td>\n",
       "      <td>36608.9449</td>\n",
       "      <td>7.559864</td>\n",
       "      <td>99.8761</td>\n",
       "      <td>3.9064</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1600798</td>\n",
       "      <td>je</td>\n",
       "      <td>1600798</td>\n",
       "      <td>.VNW.SPEC.N.BW.LID.</td>\n",
       "      <td>.1600798.72.15.2.1.</td>\n",
       "      <td>.1600798.72.50.2.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het</td>\n",
       "      <td>1068396</td>\n",
       "      <td>8066</td>\n",
       "      <td>780771</td>\n",
       "      <td>5578</td>\n",
       "      <td>1913811</td>\n",
       "      <td>24431.9717</td>\n",
       "      <td>7.384235</td>\n",
       "      <td>99.9504</td>\n",
       "      <td>3.9067</td>\n",
       "      <td>VNW</td>\n",
       "      <td>735390</td>\n",
       "      <td>het</td>\n",
       "      <td>735395</td>\n",
       "      <td>.VNW.LID.SPEC.WW.N.</td>\n",
       "      <td>.735390.332929.53.22.2.</td>\n",
       "      <td>.735395.332929.53.845403.31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>1061177</td>\n",
       "      <td>8070</td>\n",
       "      <td>903872</td>\n",
       "      <td>6512</td>\n",
       "      <td>1063827</td>\n",
       "      <td>24266.8883</td>\n",
       "      <td>7.381291</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.9069</td>\n",
       "      <td>LID</td>\n",
       "      <td>1060098</td>\n",
       "      <td>de</td>\n",
       "      <td>1062748</td>\n",
       "      <td>.LID.VNW.SPEC.VZ.</td>\n",
       "      <td>.1060098.806.272.1.</td>\n",
       "      <td>.1062748.806.272.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dat</td>\n",
       "      <td>965424</td>\n",
       "      <td>8063</td>\n",
       "      <td>715570</td>\n",
       "      <td>6107</td>\n",
       "      <td>965431</td>\n",
       "      <td>22077.2184</td>\n",
       "      <td>7.340221</td>\n",
       "      <td>99.9133</td>\n",
       "      <td>3.9066</td>\n",
       "      <td>VNW</td>\n",
       "      <td>532576</td>\n",
       "      <td>dat</td>\n",
       "      <td>532576</td>\n",
       "      <td>.VNW.VG.SPEC.N.WW.</td>\n",
       "      <td>.532576.432794.51.2.1.</td>\n",
       "      <td>.532576.432794.51.9.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432113</th>\n",
       "      <td>aaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432114</th>\n",
       "      <td>aaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432115</th>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432116</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432117</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271227 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  FREQcount  CDcount  FREQlow  CDlow  FREQlemma  \\\n",
       "0                 ik    1744062     8054   778704   3125    1744527   \n",
       "1                 je    1600888     8060  1315051   6535    1600923   \n",
       "2                het    1068396     8066   780771   5578    1913811   \n",
       "3                 de    1061177     8070   903872   6512    1063827   \n",
       "4                dat     965424     8063   715570   6107     965431   \n",
       "...              ...        ...      ...      ...    ...        ...   \n",
       "432113  aaaaaaaaaaaa          1        1        0      0          1   \n",
       "432114   aaaaaaaaaaa          1        1        0      0          1   \n",
       "432115       aaaaaaa          1        1        0      0          1   \n",
       "432116         aaaaa          1        1        0      0          1   \n",
       "432117          aaaa          1        1        0      0          1   \n",
       "\n",
       "         SUBTLEXWF      Zipf  SUBTLEXCD  Lg10CD dominant.pos  \\\n",
       "0       39883.0334  7.597064    99.8017  3.9061          VNW   \n",
       "1       36608.9449  7.559864    99.8761  3.9064          VNW   \n",
       "2       24431.9717  7.384235    99.9504  3.9067          VNW   \n",
       "3       24266.8883  7.381291   100.0000  3.9069          LID   \n",
       "4       22077.2184  7.340221    99.9133  3.9066          VNW   \n",
       "...            ...       ...        ...     ...          ...   \n",
       "432113      0.0229  1.656532     0.0124  0.3010            N   \n",
       "432114      0.0229  1.656532     0.0124  0.3010         SPEC   \n",
       "432115      0.0229  1.656532     0.0124  0.3010            N   \n",
       "432116      0.0229  1.656532     0.0124  0.3010            N   \n",
       "432117      0.0229  1.656532     0.0124  0.3010            N   \n",
       "\n",
       "        dominant.pos.freq dominant.pos.lemma  dominant.pos.lemma.freq  \\\n",
       "0                 1743609                 ik                  1743944   \n",
       "1                 1600798                 je                  1600798   \n",
       "2                  735390                het                   735395   \n",
       "3                 1060098                 de                  1062748   \n",
       "4                  532576                dat                   532576   \n",
       "...                   ...                ...                      ...   \n",
       "432113                  1       aaaaaaaaaaaa                        1   \n",
       "432114                  1        aaaaaaaaaaa                        1   \n",
       "432115                  1            aaaaaaa                        1   \n",
       "432116                  1              aaaaa                        1   \n",
       "432117                  1               aaaa                        1   \n",
       "\n",
       "                    all.pos             all.pos.freq  \\\n",
       "0           .VNW.SPEC.N.VZ.        .1743609.448.4.1.   \n",
       "1       .VNW.SPEC.N.BW.LID.      .1600798.72.15.2.1.   \n",
       "2       .VNW.LID.SPEC.WW.N.  .735390.332929.53.22.2.   \n",
       "3         .LID.VNW.SPEC.VZ.      .1060098.806.272.1.   \n",
       "4        .VNW.VG.SPEC.N.WW.   .532576.432794.51.2.1.   \n",
       "...                     ...                      ...   \n",
       "432113                  .N.                      .1.   \n",
       "432114               .SPEC.                      .1.   \n",
       "432115                  .N.                      .1.   \n",
       "432116                  .N.                      .1.   \n",
       "432117                  .N.                      .1.   \n",
       "\n",
       "                  all.pos.lemma.freq  \n",
       "0                .1743944.448.134.1.  \n",
       "1                .1600798.72.50.2.1.  \n",
       "2       .735395.332929.53.845403.31.  \n",
       "3                .1062748.806.272.1.  \n",
       "4             .532576.432794.51.9.1.  \n",
       "...                              ...  \n",
       "432113                           .1.  \n",
       "432114                           .1.  \n",
       "432115                           .1.  \n",
       "432116                           .1.  \n",
       "432117                           .1.  \n",
       "\n",
       "[271227 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-cleaning of the subtlex dataframe\n",
    "# # Assume subtlex is a DataFrame with a 'Word' column that may contain floats/NaNs\n",
    "# Convert all items in the 'Word' column to strings, filtering out NaN values\n",
    "subtlex['Word'] = subtlex['Word'].astype(str)\n",
    "# remove all entrys with numbers or special characters\n",
    "subtlex = subtlex[~subtlex['Word'].str.contains(r'[0-9]')]\n",
    "subtlex = subtlex[~subtlex['Word'].str.contains(r'[^a-zA-Z]')]\n",
    "\n",
    "# Replace 'nan' strings with an empty string or some default word like \"unknown\"\n",
    "subtlex['Word'].replace('nan', '', inplace=True)  # This will remove NaN-like strings\n",
    "\n",
    "subtlex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBTLEX Lexical database cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status\n",
      "keep    313339\n",
      "drop    124164\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Words to Drop:\n",
      "                Word Status\n",
      "228          aan_het   drop\n",
      "374             ben.   drop\n",
      "384          in_orde   drop\n",
      "387        niet_eens   drop\n",
      "409      aan_de_hand   drop\n",
      "...              ...    ...\n",
      "437498       &_blake   drop\n",
      "437499      &_barbie   drop\n",
      "437500  &_bake_pizza   drop\n",
      "437501        &_bach   drop\n",
      "437502    &_atlantic   drop\n",
      "\n",
      "[124164 rows x 2 columns]\n",
      "\n",
      "Sample of the DataFrame:\n",
      "  Word  FREQcount  CDcount  FREQlow  CDlow  FREQlemma   SUBTLEXWF      Zipf  \\\n",
      "0   ik    1744062     8054   778704   3125    1744527  39883.0334  7.597064   \n",
      "1   je    1600888     8060  1315051   6535    1600923  36608.9449  7.559864   \n",
      "2  het    1068396     8066   780771   5578    1913811  24431.9717  7.384235   \n",
      "3   de    1061177     8070   903872   6512    1063827  24266.8883  7.381291   \n",
      "4  dat     965424     8063   715570   6107     965431  22077.2184  7.340221   \n",
      "\n",
      "   SUBTLEXCD  Lg10CD dominant.pos  dominant.pos.freq dominant.pos.lemma  \\\n",
      "0    99.8017  3.9061          VNW            1743609                 ik   \n",
      "1    99.8761  3.9064          VNW            1600798                 je   \n",
      "2    99.9504  3.9067          VNW             735390                het   \n",
      "3   100.0000  3.9069          LID            1060098                 de   \n",
      "4    99.9133  3.9066          VNW             532576                dat   \n",
      "\n",
      "   dominant.pos.lemma.freq              all.pos             all.pos.freq  \\\n",
      "0                  1743944      .VNW.SPEC.N.VZ.        .1743609.448.4.1.   \n",
      "1                  1600798  .VNW.SPEC.N.BW.LID.      .1600798.72.15.2.1.   \n",
      "2                   735395  .VNW.LID.SPEC.WW.N.  .735390.332929.53.22.2.   \n",
      "3                  1062748    .LID.VNW.SPEC.VZ.      .1060098.806.272.1.   \n",
      "4                   532576   .VNW.VG.SPEC.N.WW.   .532576.432794.51.2.1.   \n",
      "\n",
      "             all.pos.lemma.freq Status  \n",
      "0           .1743944.448.134.1.   keep  \n",
      "1           .1600798.72.50.2.1.   keep  \n",
      "2  .735395.332929.53.845403.31.   keep  \n",
      "3           .1062748.806.272.1.   keep  \n",
      "4        .532576.432794.51.9.1.   keep  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the SUBTLEX-NL dataset\n",
    "# Replace 'subtlex-nl.csv' with the path to your dataset file\n",
    "df = subtlex\n",
    "\n",
    "# Ensure 'Word' is a string and handle NaN values\n",
    "df['Word'] = df['Word'].astype(str).fillna('').str.strip()\n",
    "\n",
    "# Initialize the 'Status' column to 'keep' by default\n",
    "df['Status'] = 'keep'\n",
    "\n",
    "# Ensure 'CDcount' and 'FREQcount' are numeric\n",
    "df['CDcount'] = pd.to_numeric(df['CDcount'], errors='coerce')\n",
    "df['FREQcount'] = pd.to_numeric(df['FREQcount'], errors='coerce')\n",
    "\n",
    "# Filter 1: Identify entries where 'Word' contains only alphabetic characters (after removing hyphens and apostrophes)\n",
    "df['Word_clean'] = df['Word'].str.replace('-', '').str.replace(\"'\", '')\n",
    "mask_alphabetic = df['Word_clean'].str.isalpha()\n",
    "\n",
    "# Filter 2: Identify entries where word length does not exceed the specified threshold\n",
    "max_word_length = 25\n",
    "mask_length = df['Word'].str.len() <= max_word_length\n",
    "\n",
    "# Filter 3: Identify entries where 'Word' does not consist entirely of punctuation marks or symbols\n",
    "# Set na=False to handle NaN values\n",
    "mask_punctuation = ~df['Word'].str.match(r'^[^\\w\\s]+$', na=False)\n",
    "\n",
    "# Filter 4: Handle 'SPEC' Part of Speech\n",
    "mask_spec = df['dominant.pos'] == 'SPEC'\n",
    "mask_spec_alphabetic = df['Word_clean'].str.isalpha()\n",
    "mask_spec_keep = ~(mask_spec & ~mask_spec_alphabetic)\n",
    "\n",
    "# Combine all masks to determine the final 'keep' status\n",
    "mask_keep = mask_alphabetic & mask_length & mask_punctuation & mask_spec_keep\n",
    "\n",
    "# Update the 'Status' column based on the combined mask\n",
    "df.loc[~mask_keep, 'Status'] = 'drop'\n",
    "\n",
    "# Remove the temporary 'Word_clean' column\n",
    "df.drop('Word_clean', axis=1, inplace=True)\n",
    "\n",
    "# Display counts of 'keep' and 'drop' entries\n",
    "print(df['Status'].value_counts())\n",
    "\n",
    "# Display the words marked as 'drop' along with their indices\n",
    "dropped_words = df[df['Status'] == 'drop']\n",
    "print(\"\\nWords to Drop:\")\n",
    "print(dropped_words[['Word', 'Status']])\n",
    "\n",
    "# Display the first few rows of the DataFrame with the 'Status' column\n",
    "print(\"\\nSample of the DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/home/neel/Desktop/MOUS_hierarchical-representations/subtlex_v2_cleaned_no_drop2.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>CDlow</th>\n",
       "      <th>FREQlemma</th>\n",
       "      <th>SUBTLEXWF</th>\n",
       "      <th>Zipf</th>\n",
       "      <th>SUBTLEXCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "      <th>dominant.pos</th>\n",
       "      <th>dominant.pos.freq</th>\n",
       "      <th>dominant.pos.lemma</th>\n",
       "      <th>dominant.pos.lemma.freq</th>\n",
       "      <th>all.pos</th>\n",
       "      <th>all.pos.freq</th>\n",
       "      <th>all.pos.lemma.freq</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ik</td>\n",
       "      <td>1744062</td>\n",
       "      <td>8054</td>\n",
       "      <td>778704</td>\n",
       "      <td>3125</td>\n",
       "      <td>1744527</td>\n",
       "      <td>39883.0334</td>\n",
       "      <td>7.597064</td>\n",
       "      <td>99.8017</td>\n",
       "      <td>3.9061</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1743609</td>\n",
       "      <td>ik</td>\n",
       "      <td>1743944</td>\n",
       "      <td>.VNW.SPEC.N.VZ.</td>\n",
       "      <td>.1743609.448.4.1.</td>\n",
       "      <td>.1743944.448.134.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>1600888</td>\n",
       "      <td>8060</td>\n",
       "      <td>1315051</td>\n",
       "      <td>6535</td>\n",
       "      <td>1600923</td>\n",
       "      <td>36608.9449</td>\n",
       "      <td>7.559864</td>\n",
       "      <td>99.8761</td>\n",
       "      <td>3.9064</td>\n",
       "      <td>VNW</td>\n",
       "      <td>1600798</td>\n",
       "      <td>je</td>\n",
       "      <td>1600798</td>\n",
       "      <td>.VNW.SPEC.N.BW.LID.</td>\n",
       "      <td>.1600798.72.15.2.1.</td>\n",
       "      <td>.1600798.72.50.2.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het</td>\n",
       "      <td>1068396</td>\n",
       "      <td>8066</td>\n",
       "      <td>780771</td>\n",
       "      <td>5578</td>\n",
       "      <td>1913811</td>\n",
       "      <td>24431.9717</td>\n",
       "      <td>7.384235</td>\n",
       "      <td>99.9504</td>\n",
       "      <td>3.9067</td>\n",
       "      <td>VNW</td>\n",
       "      <td>735390</td>\n",
       "      <td>het</td>\n",
       "      <td>735395</td>\n",
       "      <td>.VNW.LID.SPEC.WW.N.</td>\n",
       "      <td>.735390.332929.53.22.2.</td>\n",
       "      <td>.735395.332929.53.845403.31.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>1061177</td>\n",
       "      <td>8070</td>\n",
       "      <td>903872</td>\n",
       "      <td>6512</td>\n",
       "      <td>1063827</td>\n",
       "      <td>24266.8883</td>\n",
       "      <td>7.381291</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.9069</td>\n",
       "      <td>LID</td>\n",
       "      <td>1060098</td>\n",
       "      <td>de</td>\n",
       "      <td>1062748</td>\n",
       "      <td>.LID.VNW.SPEC.VZ.</td>\n",
       "      <td>.1060098.806.272.1.</td>\n",
       "      <td>.1062748.806.272.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dat</td>\n",
       "      <td>965424</td>\n",
       "      <td>8063</td>\n",
       "      <td>715570</td>\n",
       "      <td>6107</td>\n",
       "      <td>965431</td>\n",
       "      <td>22077.2184</td>\n",
       "      <td>7.340221</td>\n",
       "      <td>99.9133</td>\n",
       "      <td>3.9066</td>\n",
       "      <td>VNW</td>\n",
       "      <td>532576</td>\n",
       "      <td>dat</td>\n",
       "      <td>532576</td>\n",
       "      <td>.VNW.VG.SPEC.N.WW.</td>\n",
       "      <td>.532576.432794.51.2.1.</td>\n",
       "      <td>.532576.432794.51.9.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313334</th>\n",
       "      <td>a'trom</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>a'trom</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313335</th>\n",
       "      <td>a'tje</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>662</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>662</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.662.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313336</th>\n",
       "      <td>a'tij</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>a'tij</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313337</th>\n",
       "      <td>a'mah</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>SPEC</td>\n",
       "      <td>1</td>\n",
       "      <td>a'mah</td>\n",
       "      <td>1</td>\n",
       "      <td>.SPEC.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313338</th>\n",
       "      <td>a'-woord</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>1.656532</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>a'-woord</td>\n",
       "      <td>1</td>\n",
       "      <td>.N.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>.1.</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313339 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  FREQcount  CDcount  FREQlow  CDlow  FREQlemma   SUBTLEXWF  \\\n",
       "0             ik    1744062     8054   778704   3125    1744527  39883.0334   \n",
       "1             je    1600888     8060  1315051   6535    1600923  36608.9449   \n",
       "2            het    1068396     8066   780771   5578    1913811  24431.9717   \n",
       "3             de    1061177     8070   903872   6512    1063827  24266.8883   \n",
       "4            dat     965424     8063   715570   6107     965431  22077.2184   \n",
       "...          ...        ...      ...      ...    ...        ...         ...   \n",
       "313334    a'trom          1        1        0      0          1      0.0229   \n",
       "313335     a'tje          1        1        0      0        662      0.0229   \n",
       "313336     a'tij          1        1        1      1          1      0.0229   \n",
       "313337     a'mah          1        1        0      0          1      0.0229   \n",
       "313338  a'-woord          1        1        0      0          1      0.0229   \n",
       "\n",
       "            Zipf  SUBTLEXCD  Lg10CD dominant.pos  dominant.pos.freq  \\\n",
       "0       7.597064    99.8017  3.9061          VNW            1743609   \n",
       "1       7.559864    99.8761  3.9064          VNW            1600798   \n",
       "2       7.384235    99.9504  3.9067          VNW             735390   \n",
       "3       7.381291   100.0000  3.9069          LID            1060098   \n",
       "4       7.340221    99.9133  3.9066          VNW             532576   \n",
       "...          ...        ...     ...          ...                ...   \n",
       "313334  1.656532     0.0124  0.3010         SPEC                  1   \n",
       "313335  1.656532     0.0124  0.3010            N                  1   \n",
       "313336  1.656532     0.0124  0.3010         SPEC                  1   \n",
       "313337  1.656532     0.0124  0.3010         SPEC                  1   \n",
       "313338  1.656532     0.0124  0.3010            N                  1   \n",
       "\n",
       "       dominant.pos.lemma  dominant.pos.lemma.freq              all.pos  \\\n",
       "0                      ik                  1743944      .VNW.SPEC.N.VZ.   \n",
       "1                      je                  1600798  .VNW.SPEC.N.BW.LID.   \n",
       "2                     het                   735395  .VNW.LID.SPEC.WW.N.   \n",
       "3                      de                  1062748    .LID.VNW.SPEC.VZ.   \n",
       "4                     dat                   532576   .VNW.VG.SPEC.N.WW.   \n",
       "...                   ...                      ...                  ...   \n",
       "313334             a'trom                        1               .SPEC.   \n",
       "313335                  a                      662                  .N.   \n",
       "313336              a'tij                        1               .SPEC.   \n",
       "313337              a'mah                        1               .SPEC.   \n",
       "313338           a'-woord                        1                  .N.   \n",
       "\n",
       "                   all.pos.freq            all.pos.lemma.freq Status  \n",
       "0             .1743609.448.4.1.           .1743944.448.134.1.   keep  \n",
       "1           .1600798.72.15.2.1.           .1600798.72.50.2.1.   keep  \n",
       "2       .735390.332929.53.22.2.  .735395.332929.53.845403.31.   keep  \n",
       "3           .1060098.806.272.1.           .1062748.806.272.1.   keep  \n",
       "4        .532576.432794.51.2.1.        .532576.432794.51.9.1.   keep  \n",
       "...                         ...                           ...    ...  \n",
       "313334                      .1.                           .1.   keep  \n",
       "313335                      .1.                         .662.   keep  \n",
       "313336                      .1.                           .1.   keep  \n",
       "313337                      .1.                           .1.   keep  \n",
       "313338                      .1.                           .1.   keep  \n",
       "\n",
       "[313339 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if 'Status' in df is 'drop', drop the row\n",
    "df = df[df['Status'] != 'drop']\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, run the main function with a list of words\n",
    "subtlex['IPA'] = get_phonetic_transcriptions_parallel(list(subtlex['Word']),max_workers=8)\n",
    "\n",
    "\n",
    "\n",
    "subtlex['Syllables'] = subtlex['IPA'].apply(lambda x: syllabify_ipa(x))\n",
    "subtlex.drop(columns = ['CDcount', 'FREQlow', 'CDlow','FREQlemma'], inplace = True)\n",
    "#save the dataframe to a csv file\n",
    "subtlex.to_csv('/home/neel/Desktop/MOUS_hierarchical-representations/subtlex_v2_IPA_syllables.csv', index = False)\n",
    "subtlex = pd.read_csv('/home/neel/Desktop/MOUS_hierarchical-representations/subtlex_v2_IPA_syllables.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
