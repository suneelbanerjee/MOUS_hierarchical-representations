{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_clusters(tmap_path, output_dir, threshold, extent_threshold=10):\n",
    "    \"\"\"\n",
    "    Separates non-contiguous clusters in a T-map into individual NIfTI masks,\n",
    "    applying a voxel count threshold (extent threshold).\n",
    "\n",
    "    Parameters:\n",
    "        tmap_path (str): Path to the input T-map NIfTI file.\n",
    "        output_dir (str): Directory to save the output NIfTI masks.\n",
    "        threshold (float): Threshold value to apply to the T-map.\n",
    "        extent_threshold (int): Minimum number of voxels for a cluster to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list of cluster paths, affine transformation matrix)\n",
    "    \"\"\"\n",
    "    # Load the T-map\n",
    "    tmap_img = nib.load(tmap_path)\n",
    "    tmap_data = tmap_img.get_fdata()\n",
    "\n",
    "    # Apply threshold\n",
    "    thresholded_data = tmap_data > threshold\n",
    "\n",
    "    # Label clusters\n",
    "    labeled_data, num_clusters = label(thresholded_data)\n",
    "    print(f\"Found {num_clusters} clusters (before extent threshold).\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save each cluster that meets the extent threshold\n",
    "    cluster_paths = []\n",
    "    retained_clusters = 0\n",
    "    for cluster_id in range(1, num_clusters + 1):\n",
    "        cluster_mask = (labeled_data == cluster_id).astype(np.int16)\n",
    "        # Count the number of voxels in the cluster\n",
    "        voxel_count = np.sum(cluster_mask)\n",
    "\n",
    "        # Skip clusters that do not meet the extent threshold\n",
    "        if voxel_count < extent_threshold:\n",
    "            continue\n",
    "\n",
    "        # Save the cluster mask\n",
    "        cluster_img = nib.Nifti1Image(cluster_mask, affine=tmap_img.affine, header=tmap_img.header)\n",
    "        output_path = os.path.join(output_dir, f\"cluster_{retained_clusters + 1}.nii\")\n",
    "        nib.save(cluster_img, output_path)\n",
    "        cluster_paths.append(output_path)\n",
    "        retained_clusters += 1\n",
    "        print(f\"Saved cluster {retained_clusters} with {voxel_count} voxels to {output_path}\")\n",
    "\n",
    "    print(f\"Retained {retained_clusters} clusters (after extent threshold).\")\n",
    "\n",
    "    # Return cluster paths and the affine matrix\n",
    "    return cluster_paths, tmap_img.affine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centroids_and_peaks(cluster_paths, tmap_path):\n",
    "    \"\"\"\n",
    "    Calculates the centroid and peak coordinates of each cluster.\n",
    "\n",
    "    Parameters:\n",
    "        cluster_paths (list): List of paths to cluster NIfTI masks.\n",
    "        tmap_path (str): Path to the original T-map NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries for each cluster containing centroid and peak coordinates.\n",
    "    \"\"\"\n",
    "    # Load the T-map\n",
    "    tmap_img = nib.load(tmap_path)\n",
    "    tmap_data = tmap_img.get_fdata()\n",
    "\n",
    "    results = []\n",
    "    for cluster_path in cluster_paths:\n",
    "        # Load the cluster mask\n",
    "        cluster_img = nib.load(cluster_path)\n",
    "        cluster_data = cluster_img.get_fdata()\n",
    "\n",
    "        # Mask the T-map with the cluster mask\n",
    "        weighted_data = cluster_data * tmap_data\n",
    "\n",
    "        # Find voxel coordinates\n",
    "        coords = np.array(np.nonzero(cluster_data))\n",
    "        weights = weighted_data[cluster_data > 0]\n",
    "\n",
    "        # Calculate the weighted centroid\n",
    "        if weights.sum() > 0:\n",
    "            centroid = np.average(coords, axis=1, weights=weights)\n",
    "            # Transform centroid to world coordinates\n",
    "            centroid_world = nib.affines.apply_affine(tmap_img.affine, centroid)\n",
    "        else:\n",
    "            centroid_world = (np.nan, np.nan, np.nan)  # In case of no weights\n",
    "\n",
    "        # Find the peak coordinate (voxel with the highest T-statistic)\n",
    "        peak_voxel_index = np.unravel_index(np.argmax(weighted_data, axis=None), cluster_data.shape)\n",
    "        peak_world = nib.affines.apply_affine(tmap_img.affine, peak_voxel_index)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"centroid\": tuple(centroid_world),\n",
    "            \"peak\": tuple(peak_world)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Updated to include peak T value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing T-map: /Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/SPM_syllables_guslatho_Log10/spmT_0001.nii\n",
      "Using threshold: 7.89\n",
      "Saving results to: /Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/SPM_syllables_guslatho_Log10/roi/cluster_centroids.csv\n",
      "Found 2 clusters (before extent threshold).\n",
      "Saved cluster 1 with 870 voxels to /Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/SPM_syllables_guslatho_Log10/roi/cluster_1.nii\n",
      "Saved cluster 2 with 618 voxels to /Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/SPM_syllables_guslatho_Log10/roi/cluster_2.nii\n",
      "Retained 2 clusters (after extent threshold).\n",
      "Cluster 1:\n",
      "  Centroid = [-61, -17, 1]\n",
      "  Peak = [-64, -12, -2]\n",
      "  Peak T-value = 12.19\n",
      "  Extent = 870 voxels\n",
      "Cluster 2:\n",
      "  Centroid = [63, -11, 0]\n",
      "  Peak = [64, -4, -4]\n",
      "  Peak T-value = 11.25\n",
      "  Extent = 618 voxels\n",
      "Processing completed for /Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/SPM_syllables_guslatho_Log10\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/renderings/u_threshold.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Read threshold value\u001b[39;00m\n\u001b[1;32m     22\u001b[0m u_threshold_path \u001b[38;5;241m=\u001b[39m spm_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_threshold.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu_threshold_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     24\u001b[0m     u_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Define T-map path and save path\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/neel/Desktop/SPM_Aug_2025/SYLLABLES/renderings/u_threshold.txt'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Define second-level analysis directory\n",
    "second_level = Path('/Users/neel/Desktop/SPM_Aug_2025/SYLLABLES')\n",
    "\n",
    "for spm_dir in second_level.iterdir():\n",
    "    if spm_dir.is_dir():\n",
    "        roi_output_dir = spm_dir / 'roi'\n",
    "        \n",
    "        # Ensure the ROI directory is clean\n",
    "        if roi_output_dir.exists():\n",
    "            for file in roi_output_dir.iterdir():\n",
    "                file.unlink()\n",
    "        else:\n",
    "            roi_output_dir.mkdir(parents=True)\n",
    "        \n",
    "        # Read threshold value\n",
    "        u_threshold_path = spm_dir / 'u_threshold.txt'\n",
    "        with open(u_threshold_path, 'r') as f:\n",
    "            u_threshold = float(f.read().strip())\n",
    "        \n",
    "        # Define T-map path and save path\n",
    "        tmap = spm_dir / 'spmT_0001.nii'\n",
    "        save_path = roi_output_dir / 'cluster_centroids.csv'\n",
    "        \n",
    "        print(f\"Processing T-map: {tmap}\")\n",
    "        print(f\"Using threshold: {u_threshold}\")\n",
    "        print(f\"Saving results to: {save_path}\")\n",
    "        \n",
    "        # Process clusters\n",
    "        cluster_paths, affine = separate_clusters(str(tmap), str(roi_output_dir), threshold=u_threshold, extent_threshold=20)\n",
    "        results = calculate_centroids_and_peaks(cluster_paths, str(tmap))\n",
    "        \n",
    "        # Compute peak T-values and cluster extents\n",
    "        tmap_img = nib.load(tmap)\n",
    "        tmap_data = tmap_img.get_fdata()\n",
    "        \n",
    "        for i, (cluster_path, result) in enumerate(zip(cluster_paths, results)):\n",
    "            peak_voxel = np.round(nib.affines.apply_affine(np.linalg.inv(tmap_img.affine), result[\"peak\"])).astype(int)\n",
    "            if (0 <= peak_voxel[0] < tmap_data.shape[0] and\n",
    "                0 <= peak_voxel[1] < tmap_data.shape[1] and\n",
    "                0 <= peak_voxel[2] < tmap_data.shape[2]):\n",
    "                result[\"peak_t_value\"] = tmap_data[tuple(peak_voxel)]\n",
    "            else:\n",
    "                result[\"peak_t_value\"] = float('nan')\n",
    "            \n",
    "            # Compute cluster extent\n",
    "            cluster_img = nib.load(cluster_path)\n",
    "            cluster_data = cluster_img.get_fdata()\n",
    "            result[\"extent\"] = int(np.sum(cluster_data > 0))\n",
    "        \n",
    "        # Sort results by peak T-value in descending order\n",
    "        sorted_results = sorted(results, key=lambda x: x['peak_t_value'], reverse=True)\n",
    "        \n",
    "        # Reassign cluster numbers in order\n",
    "        for i, result in enumerate(sorted_results, start=1):\n",
    "            result['Cluster #'] = i\n",
    "        \n",
    "        # Print sorted results\n",
    "        for result in sorted_results:\n",
    "            print(f\"Cluster {result['Cluster #']}:\")\n",
    "            print(f\"  Centroid = {[round(coord) for coord in result['centroid']]}\")\n",
    "            print(f\"  Peak = {[round(coord) for coord in result['peak']]}\")\n",
    "            print(f\"  Peak T-value = {round(result['peak_t_value'], 2)}\")\n",
    "            print(f\"  Extent = {result['extent']} voxels\")\n",
    "        \n",
    "        # Save sorted results to CSV\n",
    "        with open(save_path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['Cluster #', 'Centroid', 'Peak', 'Peak T-value', 'Extent']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for result in sorted_results:\n",
    "                writer.writerow({\n",
    "                    'Cluster #': result['Cluster #'],\n",
    "                    'Centroid': [round(coord) for coord in result['centroid']],\n",
    "                    'Peak': [round(coord) for coord in result['peak']],\n",
    "                    'Peak T-value': round(result['peak_t_value'], 2),\n",
    "                    'Extent': result['extent']\n",
    "                })\n",
    "        \n",
    "        print(f\"Processing completed for {spm_dir}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# spm_dir = '/home/neel/Documents/SPM_results/second_level/SPM-A_II_syllables_IPA_eSpeak_ijfix2'\n",
    "# roi_output_dir = str(Path(spm_dir) / 'roi')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if not os.path.exists(roi_output_dir):\n",
    "#     os.makedirs(roi_output_dir)\n",
    "# tmap = str(Path(spm_dir) / 'spmT_0001.nii')\n",
    "# print(tmap)\n",
    "# save_path = str(Path(roi_output_dir) / 'cluster_centroids.csv')\n",
    "# print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #delete all the contents of the roi_output_dir before running the code\n",
    "# for file in os.listdir(roi_output_dir):\n",
    "#     os.remove(os.path.join(roi_output_dir, file))\n",
    "# cluster_paths, affine = separate_clusters(tmap, roi_output_dir, 5.409,extent_threshold=20)\n",
    "# results = calculate_centroids_and_peaks(cluster_paths, tmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Calculate peak T-values and store results\n",
    "# sorted_results = []\n",
    "# for i, result in enumerate(results, start=1):\n",
    "#     centroid = [round(coord) for coord in result[\"centroid\"]]\n",
    "#     peak = [round(coord) for coord in result[\"peak\"]]\n",
    "    \n",
    "#     # Load the T-map to get the peak T-value\n",
    "#     tmap_img = nib.load(tmap)\n",
    "#     tmap_data = tmap_img.get_fdata()\n",
    "    \n",
    "#     # Convert the peak coordinate from world space to voxel space\n",
    "#     peak_voxel = np.round(nib.affines.apply_affine(np.linalg.inv(tmap_img.affine), result[\"peak\"])).astype(int)\n",
    "    \n",
    "#     # Ensure the voxel indices are within bounds\n",
    "#     if (0 <= peak_voxel[0] < tmap_data.shape[0] and\n",
    "#         0 <= peak_voxel[1] < tmap_data.shape[1] and\n",
    "#         0 <= peak_voxel[2] < tmap_data.shape[2]):\n",
    "#         peak_t_value = tmap_data[tuple(peak_voxel)]\n",
    "#     else:\n",
    "#         peak_t_value = float('nan')  # Out of bounds, assign NaN\n",
    "\n",
    "#     # Calculate cluster size in voxels\n",
    "#     cluster_path = cluster_paths[i - 1]\n",
    "#     cluster_img = nib.load(cluster_path)\n",
    "#     cluster_data = cluster_img.get_fdata()\n",
    "#     cluster_size = int(np.sum(cluster_data > 0))  # Count non-zero voxels\n",
    "\n",
    "#     sorted_results.append({\n",
    "#         'Cluster #': i,\n",
    "#         'Centroid': centroid,\n",
    "#         'Peak': peak,\n",
    "#         'Peak T-value': peak_t_value,\n",
    "#         'Extent': cluster_size\n",
    "#     })\n",
    "\n",
    "# # Sort results by peak T-value in descending order\n",
    "# sorted_results.sort(key=lambda x: x['Peak T-value'], reverse=True)\n",
    "\n",
    "# # Reassign cluster numbers in order\n",
    "# for i, result in enumerate(sorted_results, start=1):\n",
    "#     result['Cluster #'] = i\n",
    "\n",
    "# # Print sorted results\n",
    "# for result in sorted_results:\n",
    "#     print(f\"Cluster {result['Cluster #']}:\")\n",
    "#     print(f\"  Centroid = {result['Centroid']}\")\n",
    "#     print(f\"  Peak = {result['Peak']}\")\n",
    "#     print(f\"  Peak T-value = {round(result['Peak T-value'], 2)}\")\n",
    "#     print(f\"  Extent = {result['Extent']} voxels\")\n",
    "\n",
    "# # Save sorted results to a CSV file\n",
    "# with open(save_path, 'w', newline='') as csvfile:\n",
    "#     fieldnames = ['Cluster #', 'Centroid', 'Peak', 'Peak T-value', 'Extent']\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#     writer.writeheader()\n",
    "#     for result in sorted_results:\n",
    "#         writer.writerow({\n",
    "#             'Cluster #': result['Cluster #'],\n",
    "#             'Centroid': result['Centroid'],\n",
    "#             'Peak': result['Peak'],\n",
    "#             'Peak T-value': round(result['Peak T-value'], 2),\n",
    "#             'Extent': result['Extent']\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
